<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>阔落煮酒</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://chenyin.top/"/>
  <updated>2019-04-08T09:49:39.052Z</updated>
  <id>http://chenyin.top/</id>
  
  <author>
    <name>Barwe</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>photos</title>
    <link href="http://chenyin.top/uncategorized/20190408-undefined.html"/>
    <id>http://chenyin.top/uncategorized/20190408-undefined.html</id>
    <published>2019-04-08T09:49:39.000Z</published>
    <updated>2019-04-08T09:49:39.052Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>降维04 - TSNE引领时尚</title>
    <link href="http://chenyin.top/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/20190328-acd8.html"/>
    <id>http://chenyin.top/机器学习与算法基础/20190328-acd8.html</id>
    <published>2019-03-28T03:12:08.000Z</published>
    <updated>2019-03-29T09:01:12.294Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/111403.png" alt=""><br><strong>t-SNE</strong> (<strong>t-distributed Stochastic Neighbor Embedding</strong>) 是目前来说效果较好的数据降维与可视化方法，但是大量占用内存、计算时间长的缺点也很突出。<br>相比于SNE，t-SNE的主要优化有：联合概率替代条件概率、低维空间下使用t分布代替高斯分布。<a href="#ref1">[1]</a><br><a id="more"></a></p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><h2 id="可视化"><a href="#可视化" class="headerlink" title="可视化"></a>可视化</h2><p>早期的<strong>可视化 (Visualization)</strong> 工具<u>不负责解释数据</u>，这就限制了这些工具在真实世界数据上的应用，因为我们要想解释数据，我们还是只能靠人眼看。相比于能解释数据的监督学习而言，可视化只需要展示训练数据，而不需要训练模型使它能够拟合到测试数据集。可视化的任务简单许多。<a href="#ref2">[2]</a></p><h2 id="线性降维"><a href="#线性降维" class="headerlink" title="线性降维"></a>线性降维</h2><p> 将数据从高位空间映射到低维空间的过程我们称之为 <strong>map</strong>，相应的，低维空间中的映射点被称之为 <strong>map points</strong>。降维算法已经注意到，要将高维空间中的数据结构问题尽可能的保留到低维空间。</p><p> 但是传统的<strong>线性降维 (Linear dimentionality reduction)</strong>  算法，例如PCA、MDS，更加侧重<u>在低维空间中保持高维空间中的<strong>差异性</strong></u>，即尽可能地分开数据。同时它们更加关注数据地<strong>全局特征</strong>，这点与非线性降维算法显著不同。</p><h2 id="非线性降维"><a href="#非线性降维" class="headerlink" title="非线性降维"></a>非线性降维</h2><p>大部分<strong>非线性降维 (non-linear dimentionality reduction)</strong> 算法关注的是 <u>在低维空间中保持高维空间地<strong>局部特征</strong></u>。这就意味着，它们不能同时关注数据的全局特征和局部特征。全局特征就是基于所有数据进行的解释，比如聚类结果就是基于所有数据进行的，理想情况下每个数据点都能找到它自己所属的类；局部特征只是基于部分数据点进行的推导，比如在SNE算法中，总是计算离中心点欧式距离小的部分点进行下降，它关注的是以中心点为圆心，以有限长度为半径的（超）球体内的点。</p><p>下面7个常见的非线性降维算法，它们在局部特征提取上都是很优秀的：Sammon mapping <a href="#ref3">[3]</a>, CCA <a href="#ref4">[4]</a>, SNE <a href="#ref5">[5]</a>, Isomap <a href="#ref6">[6]</a>, MVU <a href="#ref7">[7]</a>, LLE <a href="#ref8">[8]</a>, Laplacian Eigenmaps <a href="#ref9">[9]</a>。</p><h2 id="t-SNE"><a href="#t-SNE" class="headerlink" title="t-SNE"></a>t-SNE</h2><p>t-SNE继承自SNE算法，同样是非线性降维，它的优势在于：能够保持大部分局部特征到低维空间，同时不丢失全局特征（例如聚类）。</p><p>与SNE一样，t-SNE的思想还是计算两个点间的<strong>相似度</strong> (similarity)。</p><h1 id="方法论"><a href="#方法论" class="headerlink" title="方法论"></a>方法论</h1><p>SNE尽管能得到比较好的可视化结果，但是它的损失函数难以优化，并且还存在 <strong>crowding problem (拥挤问题)</strong> 。相比之下，t-SNE能缓和上面提到的所有问题（优化问题和拥挤问题），与SNE相比，t-SNE主要在两个方面进行改进：<br>1.使用<strong>对称</strong>的损失函数，新的损失函数求导会更加容易。<a href="#ref10">[10]</a><br>2.计算低维空间中两点的相似度使用<strong>t分布</strong>而不是高斯分布，t分布是一种<a href="https://en.wikipedia.org/wiki/Heavy-tailed_distribution" target="_blank" rel="noopener"><strong>重尾分布 (heavy-tailed distribution)</strong></a>，它能够有效缓解拥挤问题和优化问题，后面将会详细介绍。</p><h2 id="优化SNE成对称结构"><a href="#优化SNE成对称结构" class="headerlink" title="优化SNE成对称结构"></a>优化SNE成对称结构</h2><p><strong>联合概率替换条件概率</strong></p><p>在SNE中我们通过<strong>条件概率</strong>分别计算高维空间和低维空间中<strong>点对</strong>间的相似度：<br>$$\begin{cases}<br>&amp; p_{ij}=p(x_j|x_i)=\frac{\exp(-||x_i-x_j||^2)}{\sum_{k{\ne}i}{\exp(-||x_i-x_k||^2)}} \\<br>&amp; q_{ij}=q(y_j|y_i) = \frac {\exp{(-||y_i-y_j||^2)}} {\sum_{k{\ne}i}{\exp{(-||y_i-y_k||^2)}}}<br>\end{cases}$$</p><p>然后在t-SNE中我们将条件概率换成<strong>联合概率</strong>：<br>$$\begin{cases}<br>&amp; p_{ij}=p(x_j,x_i)=\frac{\exp(-||x_i-x_j||^2)}{\sum_{m{\ne}n}{\exp(-||x_m-x_n||^2)}} \\<br>&amp; q_{ij}=q(y_j,y_i) = \frac {\exp{(-||y_i-y_j||^2)}} {\sum_{m{\ne}n}{\exp{(-||y_m-y_n||^2)}}}<br>\end{cases}$$</p><p>注意上面两种表述方式的分母的差异：</p><ul><li>条件概率的分母是中心点 $x_i$ 与其它所有点的相似度之和;</li><li>联合概率的分母没有中心点一说，计算的是所有点对（n个数据点有 $C_n^2$ 个点对）的相似度之和。</li><li>条件概率中 $p_{ij}{\ne}p_{ji}$，而联合概率中 $p_{ij}=p_{ji}$（q同理），这正好也与分母的这种差异吻合。</li></ul><p><strong>注意到联合概率算法会产生一个条件概率算法不会遇到的问题：离群点。</strong></p><p>观察上面的联合概率公式，对于离群点 $x_i$，所有与它配对计算出来的 $p_{ij}$ 或者 $p_{ji}$ 的 $||x_i-x_j||^2$ 将会特别大，这导致 $p_{ij}$ 或者 $p_{ji}$ 总是特别的小，即与 $x_i$ 相关的 $p_{ij}$ 或者 $p_{ji}$ 在对损失函数的贡献总是特别小。这相当于自动减小了那些低密度区域的点在损失函数中的权重，使得通过相似性确定离群点在低维空间中的位置更加困难。<br><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/103236.png" alt=""></p><p>所以呢，必须想办法消除这种效应，增大离群点在损失函数中的比重，文中用用条件概率公式代替上述 $p_{ij}$ 的定义，即：<br>$$\begin{cases}<br>&amp; p_{ij}=\frac{p(x_j|x_i)+p(x_i|x_j)}{2n}  \\<br>&amp; q_{ij}=q(y_j|y_i) = \frac {\exp{(-||y_i-y_j||^2)}} {\sum_{m{\ne}n}{\exp{(-||y_m-y_n||^2)}}}<br>\end{cases}$$</p><p>这样每个点 $x_i$ 对损失函数的贡献度 $p(x_i)=\sum_jp_{ij}&gt;\frac1{2n}$，这就保证了离群点的贡献不会太少。</p><p><strong>KL散度作为损失函数</strong></p><p>t-SNE仍然使用KL散度作为损失函数，所不同的是，这里求的是两个联合概率分布之间的散度：<br>$$C=KL(P||Q)=\sum_i\sum_jp_{ij}\log{\frac{p_{ij}}{q_{ij}}}$$</p><p>此时KL损失函数求导的结果更加简洁：<br>$$\frac{\partial{C}}{\partial{y_i}}=4\sum_k(p_{ik}-q_{ik})(y_i-y_k)$$</p><p>SNE求导结果为：<br>$$\frac{\partial{C}}{\partial{y_i}}=2\sum_k{(y_i-y_k)[(p_{ik}-q_{ik})+(p_{ki}-q_{ki})]}$$</p><h2 id="解决SNE的拥挤问题"><a href="#解决SNE的拥挤问题" class="headerlink" title="解决SNE的拥挤问题"></a>解决SNE的拥挤问题</h2><h3 id="什么是拥挤问题"><a href="#什么是拥挤问题" class="headerlink" title="什么是拥挤问题"></a>什么是拥挤问题</h3><h4 id="流形的直观理解"><a href="#流形的直观理解" class="headerlink" title="流形的直观理解"></a>流形的直观理解</h4><p>manifold的<a href="https://en.wikipedia.org/wiki/Manifold" target="_blank" rel="noopener">Wiki解释</a>：</p><blockquote><p>In mathematics, a manifold is a topological space that locally resembles Euclidean space near each point. </p></blockquote><p>而中文概念“流形”是由北大已故数学教授江泽涵先生提出来。江老的堂姐夫是胡适？… … 不过“流形：这个词真的很艺术，我初次见到时就感叹其形象而不能自已。流形的<a href="https://zh.wikipedia.org/wiki/%E6%B5%81%E5%BD%A2" target="_blank" rel="noopener">Wiki中文解释</a>：</p><blockquote><p>是局部具有欧几里得空间性质的空间，是欧几里得空间中的曲线、曲面等概念的推广。欧几里得空间就是最简单的流形的实例。地球表面这样的球面则是一个稍微复杂的例子。一般的流形可以通过把许多平直的片折弯并粘连而成。</p></blockquote><p><strong>为什么说二维流形面上的点距容易建模 (model)？</strong></p><p>这个问题直观上理解最是简单。首先对于欧几里得空间，我们普通人类最多能直观感受到三维。换算成黎曼空间，就意味着我们只能在三维空间中直观感不超过二维流形曲面的存在，二维流形曲面上的距离就是曲面内连接它们的最短曲线长度。经典的二维流形曲面如下（Swiss Roll 流形, <a href="http://people.cs.uchicago.edu/~dinoj/manifold/swissroll.html%29" target="_blank" rel="noopener">Swiss Roll dataset</a>）：<br><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/200300.png" alt=""></p><h4 id="为什么存在拥挤"><a href="#为什么存在拥挤" class="headerlink" title="为什么存在拥挤"></a>为什么存在拥挤</h4><p>为了便于可视化，我们会将高维流形上的点映射到二维空间，同时最大程度的保留它们的相对位置（这种每个点相对于整体数据点的定位就是一种全局特征）。然而这种映射是很难完美实现的，举个例子，十维空间（欧几里得空间或者黎曼空间）中可以很容易找到11个相互等距的点（就好比二维空间中能轻易找到三个相互等距的点一样），然而映射到二维空间是不可能找到11个相互等距的点的，势必会有一些点会相互靠近挤在一起，如下图所示：<br><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/202201.png" alt=""><br>以二维相互等距的三个点映射到一维空间为例，无论怎么努力，三点都不可能再等距。归根揭底，不同维度空间内的距离分布是不同的，降维映射难免尽如人意。</p><p>再以球内区域为例解释crowding现象：以数据点 $x_i$ 为中心的球的体积与 $r^m$ 直接相关（ $r$ 是半径，$m$ 是球所在空间的维度）。如果在十维流形曲面上数据点均匀分布在这个球中，我们试图在二维流形曲面上以 $y_i$ 为中心对与 $x_i$ 相关的两两距离进行建模。此时我们就会遇到传说中的拥挤问题：与容纳中心点附近数据点的区域相比，容纳适中距离数据点的区域显得不够用。</p><p>在均匀分布的条件下，等距点的数量与半径相关，距离越大数量越多，这意味着映射到低维空间就会越“挤”。因此如果我们想要较为准确的在二维流形曲面中对以 $x_i$ 为中心的两两距离建模，我们就必须把距离 $x_i$ 适中位置的那些点往更远的地方推置（因为太挤了）。</p><!--在SNE中，数据点 $y_i$ 与其它点之间存在一个微弱的引力，所有的力相互作用最终使所有的点**分散在**了自己的收敛位置，这使得点的分布具有连续性质，在聚类时也不会出现断层的现象。--><p>不只是SNE，其它局部特征提取算法例如Sammon mapping等也都面临着拥挤难题。</p><h3 id="怎么解决拥挤问题"><a href="#怎么解决拥挤问题" class="headerlink" title="怎么解决拥挤问题"></a>怎么解决拥挤问题</h3><p>一种叫做<strong>UNI-SNE</strong>的改良算法<a href="#ref10">[10]</a>提出了一种解决办法：给每一个两两相似度添加一个背景值，背景值采样自均匀分布并以一定的比例 $\rho$ 进行混合。由于每个点对之间都引进了背景值，因此不管低维空间中两个映射点离的多么远，$q_{ij}$ 永远不会小于 $\frac{\rho}{n(n-1)/2}$（n个数据点可组合成 $C_n^2$ 个点对）。</p><p>引进背景值导致对于高维空间中相距很远的两个数据点总有$q_{ij}&gt;p_{ij}$（$p_{ij}{\rightarrow}0$ 时 $q_{ij}{\rightarrow}\frac{\rho}{n(n-1)/2}$），这表示低维空间中点对并没有完全拟合高维空间的点对相似度，映射后相似度变小。</p><p>尽管UNI-SNE的效果比SNE好，但是其损失函数却很难优化。目前较好的优化UNI-SNE的方法是：开始的时候将背景值混合比例设为0，这实际上等效于运行SNE；当SNE开始使用<strong>模拟退火</strong>策略时增大背景值的混合比例，促进自然分类间的gaps形成。</p><p>直接优化UNI-SNE并不可行，因为低维空间中两个相距很远的映射点的 $q_{ij}$ 几乎全部来自于背景值，即高维空间中相应两点间（即使他们的 $p_{ij}$ 很大）的距离对 $q_{ij}$ 的影响很小，这使得映射后的两点间的 $q_{ij}$ 没有什么实际意义。这表示，如果一个自然类的两部分在优化早期就分开了，就再也不会再聚合在一起了。</p><h2 id="低维空间采用柯西分布表达联合概率"><a href="#低维空间采用柯西分布表达联合概率" class="headerlink" title="低维空间采用柯西分布表达联合概率"></a>低维空间采用柯西分布表达联合概率</h2><p>UNI-SNE通过添加背景值使低维空间中相距甚远的 $q_{ij}$ 不至于趋近于0。</p><p>本文提出了一种新的解决办法，采用与高斯分布性质极其相似的重尾分布计算联合概率。右重尾分布使得当随机变量取值很大时其对应的概率值高斯分布要大，典型的重尾分布是t分布，如下图所示：<br><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/103318.png" alt=""><br>t分布实际上是不同方差的高斯分布的混合分布，它的性质与高斯分布十分接近，而且更加容易计算：因为高斯分布涉及到指数运算，而t分布只需要求倒数。</p><p>这里采用的是自由度 $\nu=1$ 的t、分布，又叫做<strong>柯西分布</strong>，其概率密度函数如下：<br>$$f(x;x_0,\gamma)=\frac1{\pi\gamma[1+(\frac{x-x_o}{\gamma})]^2}$$</p><p>取 $x_0=0, \gamma=1$ 得标准柯西分布：<br>$$f(x;0,1)=\frac1{\pi[1+(x-x_0)]^2}$$</p><p>用标准柯西分布表示联合概率：<br>$$q_{ij}=\frac{(1+||y_i-y_j||^2)^{-1}}{\sum_{m{\ne}n}{(1+||y_m-y_n||^2)^{-1}}}=\frac{\sum_{m{\ne}n}(1+||y_m-y_n||^2)}{1+||y_i-y_j||^2}$$</p><p>求导结果如下：<br>$$\frac{\partial{C}}{\partial{y_i}}=4\sum_j{(p_{ij}-q_{ij})(y_i-y_j)(1+||y_i-y_j||^2)^{-1}}$$</p><h2 id="Pseudo-code"><a href="#Pseudo-code" class="headerlink" title="Pseudo code"></a>Pseudo code</h2><p>下面是<strong>精简版t-SNE算法</strong>伪代码，非常简洁：<br><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/111808.png" alt=""></p><h2 id="优化方法"><a href="#优化方法" class="headerlink" title="优化方法"></a>优化方法</h2><p><strong>添加微小的动量项可以减少到达最优解的迭代次数</strong></p><p><strong>精简版的t-SNE算法采用适应性学习率加速训练</strong>：在梯度较稳定的方向上增大学习率。<a href="#ref11">[11]</a></p><p>尽管精简版算法已经可以吊打其它非参数降维技术了，还是可以继续优化，文中提出了两个技巧：</p><p><strong>1. early compression</strong>：优化起始的时候将所有的映射点初始化在原点附近，有利于映射点移动、形成自然类。early compression通过给损失函数加上一个L2惩罚项实现。<br><strong>2. early exaggeration</strong>：在优化的初始阶段将所有的 $p_{ij}$ 扩大指定倍数加快收敛速度。</p><p>总结一下模型优化的参数配置：</p><ul><li>起始的50次迭代中将所有的 $p_{ij}$ 乘以4（这个步骤在精简版算法的伪代码中没有写出来）；</li><li>梯度下降的迭代轮数T设为1000；</li><li>动量项 $\alpha^{(t)}$ 当 $t&lt;250$ 时设为0.5，当 $t{\ge}250$ 时设为0.8；</li><li>学习率初始值设为100，每次迭代都将进行适应性更新 <a href="#ref11">[11]</a>。</li></ul><p><a href="http://ticc. uvt.nl/˜lvdrmaaten/tsne" target="_blank" rel="noopener">算法的Matlab实现</a></p><h1 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h1><p>作者分析了三个不足之处。</p><p><strong>1. 不能用于低维空间超过三维的情况</strong></p><p>因为t-SNE算法在映射空间利用了<strong>柯西分布</strong>的重尾特性解决拥挤问题，柯西分布是自由度为1的t分布，这种特性在二维空间中表现十分优异。但如果需要降到三维以上的映射空间，1自由度的t分布不能很好的保留局部特征，我们可能需要使用更多自由度的t分布。</p><p><strong>2. 本征维度诅咒</strong></p><p>t-SNE虽然能够保留全局特征，但是总体上还是基于局部特征进行的降维，这表示t-SNE对原始数据的 <strong>本征维度 (intrinsic dimentionality)</strong> 十分敏感，因为本征维度过高，我们就不能再把流形曲面的局部区域当欧几里得空间处理了，数据点间的局部特征更加复杂 <a href="#ref12">[12]</a>。不仅t-SNE，其它主流的基于局部特征提取的降维算法（如Isomap，LLe）都面临着这个诅咒。</p><p>作者提出了一种可行的办法：先用 <strong>自编码器 (autoencoder)</strong><a href="#ref13">[13]</a> 对数据进行压缩，这类模型可以大大降低原始数据的维度，同时最大保留高维数据的特征。经过编码的数据再进行t-SNE降维。</p><p><strong>3. 损失函数不凸~</strong></p><p>不幸的是当前主流降维算法使用的损失函数都是凸函数，而t-SNE优化的超参更多，这使得其损失函数是非凸的。这意味着，不同的超参取值、不同的初始化都可能收敛到不同的（局部最优）解。但是作者表示，如果固定这些超参，t-SNE就可以应用于不同的可视化任务，优化结果不会随着不同批次而发生变化。</p><p>t-SNE降维结果中点间的距离是没有实际意义的。原始的t-SNE训练很慢，后面有许多改进，比如 </p><ul><li>multiple maps of t-SNE</li><li>parametric t-SNE</li><li>… …</li></ul><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><p><span id="ref1">[1]</span> <a href="http://www.jmlr.org/papers/v9/vandermaaten08a.html" target="_blank" rel="noopener">Maaten, L. V. D., &amp; Hinton, G. (2008). <strong>Visualizing data using t-SNE</strong>. Journal of machine learning research, 9(Nov), 2579-2605.</a><br><span id="ref2">[2]</span> M.C. Ferreira de Oliveira and H. Levkowitz. <strong>From visual data exploration to visual data mining: A survey</strong>. IEEE Transactions on Visualization and Computer Graphics, 9(3):378–394, 2003.<br><span id="ref3">[3]</span> J.W. Sammon. <strong>A nonlinear mapping for data structure analysis</strong>. IEEE Transactions on Computers, 18(5):401–409, 1969.<br><span id="ref4">[4]</span> P. Demartines and J. Herault. <strong>´ Curvilinear component analysis: A self-organizing neural network for nonlinear mapping of data sets</strong>. IEEE Transactions on Neural Networks, 8(1):148–154, 1997<br><span id="ref5">[5]</span> G.E. Hinton and S.T. Roweis. <strong>Stochastic Neighbor Embedding</strong>. In Advances in Neural Information Processing Systems, volume 15, pages 833–840, Cambridge, MA, USA, 2002. The MIT Press.<br><span id="ref6">[6]</span> J.B. Tenenbaum, V. de Silva, and J.C. Langford. <strong>A global geometric framework for nonlinear dimensionality reduction</strong>. Science, 290(5500):2319–2323, 2000.<br><span id="ref7">[7]</span> K.Q. Weinberger, F. Sha, and L.K. Saul. <strong>Learning a kernel matrix for nonlinear dimensionality reduction</strong>. In Proceedings of the 21st International Confernence on Machine Learning, 2004.<br><span id="ref8">[8]</span> S.T. Roweis and L.K. Saul. <strong>Nonlinear dimensionality reduction by Locally Linear Embedding</strong>. Science, 290(5500):2323–2326, 2000.<br><span id="ref9">[9]</span> M. Belkin and P. Niyogi. <strong>Laplacian Eigenmaps and spectral techniques for embedding and clustering</strong>. In Advances in Neural Information Processing Systems, volume 14, pages 585–591, Cambridge, MA, USA, 2002. The MIT Press.<br><span id="ref10">[10]</span> J.A. Cook, I. Sutskever, A. Mnih, and G.E. Hinton. <strong>Visualizing similarity data with a mixture of maps</strong>. In Proceedings of the 11th International Conference on Artificial Intelligence and Statistics, volume 2, pages 67–74, 2007.<br><span id="ref11">[11]</span> R.A. Jacobs. <strong>Increased rates of convergence through learning rate adaptation</strong>. Neural Networks, 1: 295–307, 1988.<br><span id="ref12">[12]</span> Y. Bengio. <strong>Learning deep architectures for AI</strong>. Technical Report 1312, Universite´ de Montreal, ´ 2007.<br><span id="ref13">[13]</span> G.E. Hinton and R.R. Salakhutdinov. <strong>Reducing the dimensionality of data with neural networks</strong>. Science, 313(5786):504–507, 2006.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/111403.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;strong&gt;t-SNE&lt;/strong&gt; (&lt;strong&gt;t-distributed Stochastic Neighbor Embedding&lt;/strong&gt;) 是目前来说效果较好的数据降维与可视化方法，但是大量占用内存、计算时间长的缺点也很突出。&lt;br&gt;相比于SNE，t-SNE的主要优化有：联合概率替代条件概率、低维空间下使用t分布代替高斯分布。&lt;a href=&quot;#ref1&quot;&gt;[1]&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="机器学习与算法基础" scheme="http://chenyin.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="降维" scheme="http://chenyin.top/tags/%E9%99%8D%E7%BB%B4/"/>
    
      <category term="t-SNE" scheme="http://chenyin.top/tags/t-SNE/"/>
    
  </entry>
  
  <entry>
    <title>降维03 - SNE原理</title>
    <link href="http://chenyin.top/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/20190325-80ae.html"/>
    <id>http://chenyin.top/机器学习与算法基础/20190325-80ae.html</id>
    <published>2019-03-25T12:44:14.000Z</published>
    <updated>2019-04-08T07:32:59.777Z</updated>
    
    <content type="html"><![CDATA[<p><img src="https://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019-03-27_073917.png" width="100%"></p><blockquote><p><a href="http://papers.nips.cc/paper/2276-stochastic-neighbor-embedding.pdf" target="_blank" rel="noopener">Hinton, G. E., &amp; Roweis, S. T. (2003). <strong>Stochastic neighbor embedding</strong>. In Advances in neural information processing systems (pp. 857-864).</a></p></blockquote><p><strong>随机近邻嵌入算法 (Stochastic Neighbor Embedding, SNE)</strong> 由Hinton在2003年提出来的基于条件概率、只保留局部特征的非线性降维方法。 </p><a id="more"></a><h1 id="定义条件概率"><a href="#定义条件概率" class="headerlink" title="定义条件概率"></a>定义条件概率</h1><p>部分情况下，高维空间中两个点间的相似性可以用基于欧式距离的<strong>不相似度</strong> $d_{ij}$ 来衡量：<br>$$d_{ij}^2=\frac{||x_i-x_j||^2}{2\sigma_i^2}$$</p><p>SNE用<strong>条件概率</strong>来代替欧式距离度量两个高维数据点间的相似性。即：以点 $x_i$ 为中心，点 $x_i$ 选择 $x_j$ 作为自己邻居的概率记为 $p(x_j|x_i)$，定义<br>$$p_{ij}=p(x_j|x_i)=\frac{\exp(-d_{ij}^2)}{\sum_{k{\ne}i}{\exp(-d_{ik}^2)}} $$<br>注意这里对于 $p(x_i|x_i)$ 的理解有点怪异：它表示点 $x_i$ 选择自己作为邻居的概率，显然自己永远不可能是自己的邻居，所以 $p(x_i|x_i)=0$，而不是1。</p><h1 id="确定方差的确定"><a href="#确定方差的确定" class="headerlink" title="确定方差的确定"></a>确定方差的确定</h1><p>上式中的 $\sigma_i^2$ 是以 $x_i$ 为中心的高斯分布的<strong>方差</strong>：不同点周围的点的密度是不一样的，所以每个点的高斯分布对应的方差 $\sigma_i^2$ 也不相同，周围点密度大的中心点对应的方差应该较小。作者定义了<strong>困惑度 k (perplexity)</strong> ：手动指定的超参，代表某个点的有效邻居数，这个值对所有点都是常数。$\sigma_i^2$ 的取值将使得以点 $x_i$ 为中心选择其它所有点作为邻居的分布对应的<strong>熵</strong>等于 $\log{k}$，即<br>$$H(P_i)=-\sum_{j{\ne}i}{p(x_j|x_i)\log_2{p(x_j|x_i)}}=\log_2k$$<br>理论上可以通过上面的式子可以针对每个点 $x_i$ 解出对应的 $\sigma_i^2$。</p><p><strong>熵 $H(P_i)$ 的理解</strong></p><ul><li><strong>不确定性</strong>：熵本身就意味着不确定性，当区域点密集时，中心点位置的不确定性就小；</li><li><strong>能量</strong>：不确定性大意味着能量大，拉不住中心点，它要到处跑；</li><li><strong>有效邻居数</strong>：点密集时中心点的有效邻居就多。</li></ul><h1 id="映射到低维空间"><a href="#映射到低维空间" class="headerlink" title="映射到低维空间"></a>映射到低维空间</h1><p>在低维空间（二维或者三维）确定一点 $y_i$，它与高维空间的点 $x_i$ 对应，我们手动设置点 $y_i$ 的条件概率分布，即固定以 $y_i$ 为中心点的高斯分布对应的方差为 $\frac12$，当 $j{\ne}i$ 时：<br>$$ q_{ij}=q(y_j|y_i) = \frac {\exp{(-||y_i-y_j||^2)}} {\sum_{k{\ne}i}{\exp{(-||y_i-y_k||^2)}}} $$<br>当j=i时 $q(y_j|y_i)=0$ 。</p><p>此时，如果低维点 $y_i$ 能够正确表示高维点 $x_i$，意味着 $q(y_j|y_i)=p(x_j|x_i)$。为了使两个概率（近似）相等，我们可以最小化<strong>KL散度</strong>。损失函数如下：<br>$$C=\sum_iKL(P_i|Q_i)=\sum_i\sum_jp_{ij}\log\frac{p_{ij}}{q_{ij}}$$</p><ul><li>$P_i$ 表示：给定点 $x_i$，其它所有点的条件概率分布；</li><li>$Q_i$ 表示：给定低维空间映射点 $y_i$，其它所有低维映射点的条件概率分布。</li></ul><p>KL散度又叫<strong>相对熵</strong>，用来度量两个分布间的距离。假设P是真实分布，Q是模型分布，$KL(P|Q)$ 表示用Q表示P分布的数据所需的额外信息。   </p><p><strong>KL散度是不对称的</strong> </p><p>KL散度中包含 $\log\frac{p_{ij}}{q_{ij}}$ 意味着这个映射不是对称的，即：</p><ul><li>使用距离较小的低维点表示距离较大的高维点时，$\log\frac{p_{ij}}{q_{ij}}$ 倾向于小于0，则损失C较小；</li><li>使用距离较大的低维点表示距离较小的高维点时，$\log\frac{p_{ij}}{q_{ij}}$ 倾向于大于0，则损失C较大。</li></ul><p>这里就存在一个问题：当两个高维点距离很远，而我构造两个距离很近的低维点能够使损失函数更小，却与实际的目的不相符！所以，SNE算法使得高维空间中距离近的点在低维空间中距离仍然很近，但是远的点就嘿嘿嘿了。</p><h1 id="最小化损失函数"><a href="#最小化损失函数" class="headerlink" title="最小化损失函数"></a>最小化损失函数</h1><p>从 $q_{ij}$ 的定义式的分母部分可知，低维空间中点 $y_i$ 选择点 $y_j$ 的概率 $q_{ij}$ 与低维空间中的每一个映射点都有关系（分母起到了normalization的作用），但是求导结果却十分简洁：<br>$$\frac{\partial{C}}{\partial{y_i}}=2\sum_k{(y_i-y_k)[(p_{ik}-q_{ik})+(p_{ki}-q_{ki})]}$$</p><p>想沿着所有点以最陡梯度下降是不现实的，不仅低效，还可能陷入糟糕费解的局部最优。上面的梯度公式右边理论上是针对所有低维映射点进行迭代，但是实际上，相距较远的一堆点间的影响十分小（抽象），在计算时往往可以忽略不计，也就是说：仅仅计算与中心点相距较近的一部分点，即<strong>邻居</strong> ，这也是为什么算法中含有单词neighbour的原因了吧。</p><p>选择中心点的部分较近的邻居参与计算表示，我们只保留了中心点附近区域的特性，而忽略了整体局势，所以说SNE是保留局部特征而非全局特征的算法。这个局部特性主要反应为 $\sigma_i^2$：局部点密集方差小，局部点稀疏方法大。方差确定的方法前面已经陈述了~。</p><h2 id="带动量项的梯度更新"><a href="#带动量项的梯度更新" class="headerlink" title="带动量项的梯度更新"></a>带动量项的梯度更新</h2><p>为了加速优化过程、避免很一般的局部解，可以在每次下降时添加动量项。<strong>动量 (momentum)</strong> 的作用就是在下降到局部最优时，小球仍然具有沿切线方向的分量，这使得小球将继续朝前运动，这会有两种结果：</p><ul><li>小球越过障碍，继续前行；</li><li>小球回退，返回局部最优解；<br><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/201354.png" alt=""><br>具体的，更新公式如下：<br>$$\gamma^{(t)}=\gamma^{(t-1)}-{\eta}\frac{\partial{C}}{\partial{\gamma}}+\alpha(t)(\gamma^{(t-1)}-\gamma^{(t-2)})$$</li></ul><p>式中 $\alpha(t)$ 即动量，动量项 ($\alpha(t)(\gamma^{(t-1)}-\gamma^{(t-2)})$) 还与上一次运动幅度有关，直观的看，上一次运动越剧烈，下一次就越刹不住车。</p><h2 id="随机抖动"><a href="#随机抖动" class="headerlink" title="随机抖动"></a>随机抖动</h2><p><strong>随机抖动</strong> (random jitter) 是一种初始化技巧，即将低维空间中的所有数据点初始化在离坐标原点极近的地方。在迭代的过程中，它们将抖抖抖抖抖动直至收敛。尽管还是很慢，不过在节约时间和选择更优局部解时还是有明显提升的。</p><h2 id="模拟退火"><a href="#模拟退火" class="headerlink" title="模拟退火"></a>模拟退火</h2><p>在优化早期给每一步迭代加上高斯噪音，这可以帮助避免不好的局部最优解。随着迭代次数变多，噪音方差将逐渐减小。当方差变化非常慢时，这表明开始形成全局结构。（玄学）</p><p>然而，高斯噪音的数量和衰减速率是十分难以确定的，它们不仅与动量相关，也受学习率的影响。怎么办？多算几次！666</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;https://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019-03-27_073917.png&quot; width=&quot;100%&quot;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&quot;http://papers.nips.cc/paper/2276-stochastic-neighbor-embedding.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hinton, G. E., &amp;amp; Roweis, S. T. (2003). &lt;strong&gt;Stochastic neighbor embedding&lt;/strong&gt;. In Advances in neural information processing systems (pp. 857-864).&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;随机近邻嵌入算法 (Stochastic Neighbor Embedding, SNE)&lt;/strong&gt; 由Hinton在2003年提出来的基于条件概率、只保留局部特征的非线性降维方法。 &lt;/p&gt;
    
    </summary>
    
      <category term="机器学习与算法基础" scheme="http://chenyin.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="降维" scheme="http://chenyin.top/tags/%E9%99%8D%E7%BB%B4/"/>
    
      <category term="非线性降维" scheme="http://chenyin.top/tags/%E9%9D%9E%E7%BA%BF%E6%80%A7%E9%99%8D%E7%BB%B4/"/>
    
      <category term="SNE" scheme="http://chenyin.top/tags/SNE/"/>
    
      <category term="t-SNE" scheme="http://chenyin.top/tags/t-SNE/"/>
    
      <category term="paper" scheme="http://chenyin.top/tags/paper/"/>
    
  </entry>
  
  <entry>
    <title>降维02 - 主成分分析 (PCA)</title>
    <link href="http://chenyin.top/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/20190325-c024.html"/>
    <id>http://chenyin.top/机器学习与算法基础/20190325-c024.html</id>
    <published>2019-03-25T07:13:19.000Z</published>
    <updated>2019-03-25T07:16:18.742Z</updated>
    
    <content type="html"><![CDATA[<p>PCA的大名如雷贯耳，曾经的我也以为PCA是个什么很复杂的东西，但是学习了<strong>线性代数</strong>之后才发现，PCA的原理简单而不失优雅，粗暴而不失趣味。<a id="more"></a></p><p>PCA是最易于理解的<strong>特征提取</strong>过程：通过对原始特征的<strong>线性组合</strong>构造新的“特征”，这些特征不同于原始特征，但是又能与原始特征一样表达原始数据的信息。</p><p><strong>PCA (Primary Component Analysis, 主成分分析)</strong> 为什么叫做主成分分析呢？因为PCA构造出的新特征地位并不是等同的，即这些新特征的重要程度存在差异：</p><ul><li><strong>第一主成分 (the first component)</strong> 是新特征中最重要的特征，它在所有新特征中方差最大，这意味着它对数据变异的贡献是最大的；</li><li><strong>第二主成分 (the second component)</strong> 在保证不影响第一主成分的基础上试图解释剩下的变异（即总变异 - 第一主成分引起的变异）；</li><li><strong>第三主成分 (the third component)</strong> 在不保证第一和第二主成分呢的基础上试图解释剩下的变异（即总变异 - 第一主成分引起的变异 - 第二主成分引起的变异）;</li><li>依次类推……</li></ul><h1 id="线代原理"><a href="#线代原理" class="headerlink" title="线代原理"></a>线代原理</h1><p>预备知识：线性代数（矩阵运算、特征值&amp;特征向量、特征值分解）</p><h2 id="可对角化"><a href="#可对角化" class="headerlink" title="可对角化"></a>可对角化</h2><p>如果一个n阶方阵A相似于对角矩阵，即存在可逆矩阵$P$使得$P^{-1}AP$是对角矩阵，则称方阵A是<strong>可对角化</strong>的。</p><p><strong>n阶方阵A可对角化的充要条件是A每个特征值的几何重数与代数重数相等</strong>：<strong>代数重数</strong>指<strong>特征多项式</strong>中该特征值的幂次，<strong>几何重数</strong>指特征值对应的线性无关的特征向量的个数。</p><p><strong>n阶方阵A可对角化的充要条件是A有n个线性无关的特征向量</strong>：几何重数与代数重数相等意味着n个线性无关的特征向量。</p><p>即使方阵A可逆也不能保证每个特征值的代数重数与几何重数相等，因此A可逆不是A可对角化的充要条件！</p><h2 id="特征值分解"><a href="#特征值分解" class="headerlink" title="特征值分解"></a>特征值分解</h2><p>如果矩阵A是一个<strong>可对角化</strong>的方阵，它就可以进行特征值分解，即A可表示为：<br>$$A=Q{\Lambda}Q^{-1}$$<br>其中</p><ul><li>$Q$ 是n阶方阵，它的n个列向量是方阵A的n个特征向量</li><li>$\Lambda$ 是对角方阵，对角线元素是方阵A的特征值，其位置与 $Q$ 中的特征向量位置相对应</li></ul><p>特征值分解的应用？求逆。<br>如果方阵A是<strong>非奇异矩阵</strong>（即可以进行特征值分解且特征值不含0），则 $A^{-1}=Q{\Lambda}^{-1}Q^{-1}$，其中 $[{\Lambda}^{-1}]_{ii}=\frac1{\lambda_i}$。</p><h2 id="奇异值分解"><a href="#奇异值分解" class="headerlink" title="奇异值分解"></a>奇异值分解</h2><p>特征值分解对A的要求格外严格：可逆、特征值不含0、方阵……<br>放松特征值分解的限制，将A扩展到任意 $m{\times}n$ 的矩阵即得到 <strong>奇异值分解 (Singular Value Decomposition, SVD)</strong> 。</p><p>假设M是定义在<strong>实数域</strong>或者<strong>复数域</strong>上的 $m{\times}n$ 阶的矩阵：<br>$$M=U{\Sigma}V^\ast$$<br>其中</p><ul><li>U是 $m{\times}m$ 阶<strong>酉矩阵</strong>：U的m个列向量实际上是 $M^{\ast}M$ 的特征向量，称为M的<strong>左奇异向量</strong>。</li><li>$\Sigma$ 是 $m{\times}n$ 阶<strong>非负实数对角矩阵</strong>：对角线元素称为M的<strong>奇异值</strong>，一般情况下奇异值按<strong>从大到小</strong>的顺序排列！</li><li>$V^\ast$ 是 $V$ 的<strong>共轭转置</strong>，是 $n{\times}n$ 阶<strong>酉矩阵</strong>：V的n个列向量实际上是 $MM^\ast$ 的特征向量，称为M的<strong>右奇异向量</strong>。</li></ul><blockquote><p><strong>共轭转置</strong>：共轭转置与转置是两个概念，当矩阵定义在实数域上时二者结果相同，矩阵A的共轭转置记为 $A^\ast$，定义如下：<br>$$A^\ast=(\overline{A})^T=\overline{A^T}$$<br>其中，$\overline{A}$ 表示对A的元素<strong>复共轭</strong>，当A定义在实数域时 $\overline{A}=A$。</p></blockquote><p>当矩阵M定义在实数域时有：<br>$$M=U{\Sigma}V^T$$<br>我们在应用SVD时一般都是定义在实数域上的哟~</p><h2 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h2><p>上面提到了对于任意 $m{\times}n$ 阶矩阵M的SVD分解：<br>$$M_{m{\times}n}=U_{m{\times}m}{\Sigma_{m{\times}n}}V_{n{\times}n}^T$$<br>直观图如下（这里假设样本数量m多于特征数量n，这意味着M有n个奇异值）：<br><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/2019-03-25_142825.png" alt=""><br>其中 $\Sigma$ 矩阵很有意思，当m&gt;n时，矩阵 $\Sigma_{m{\times}n}$ 中只有子矩阵 $\Sigma_{n{\times}n}$ 的对角线上的值不为0，如下图所示：<br><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/2019-03-25_144213.png" alt=""></p><p>以scRNA测序为例：假设在表达谱矩阵中，一行表示一个细胞中不同基因的表达量，一列表示一个基因在不同细胞中的表达量。这与我们的习惯（一列表示一个细胞，一行表示一个基因）有所不同！</p><p>对应到上述SVD分解式我们发现，n表示细胞数量，m表示基因数量。我们降维的结果肯定是要保证细胞总数m不变，而将基因数目从n减小到k。</p><p>具体的，取 $\Sigma$ 中最大的k个奇异值，即取 $\Sigma_{k{\times}k}$ 子矩阵，相应的取U的前k列和V的前k列（即$V^\ast$的前k行），即：<br><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/2019-03-25_150510.png" alt=""><br>此时<br>$$M_{m{\times}n}=U_{m{\times}k}{\Sigma_{k{\times}k}}V_{k{\times}n}^T$$<br>上式中的 $U_{m{\times}k}$ 就是 $M_{m{\times}n}$ 从n维特征空间降到k维特征空间的结果。注意矩阵 $U_{m{\times}k}$ 的k个列向量并不在矩阵  $M_{m{\times}n}$ 中，而是M中的n个列向量线性组合的结果。</p><h1 id="工具"><a href="#工具" class="headerlink" title="工具"></a>工具</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># in python</span></span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;PCA的大名如雷贯耳，曾经的我也以为PCA是个什么很复杂的东西，但是学习了&lt;strong&gt;线性代数&lt;/strong&gt;之后才发现，PCA的原理简单而不失优雅，粗暴而不失趣味。
    
    </summary>
    
      <category term="机器学习与算法基础" scheme="http://chenyin.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="降维" scheme="http://chenyin.top/tags/%E9%99%8D%E7%BB%B4/"/>
    
      <category term="PCA" scheme="http://chenyin.top/tags/PCA/"/>
    
  </entry>
  
  <entry>
    <title>降维01 - 特征选择和特征提取</title>
    <link href="http://chenyin.top/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/20190325-d2ce.html"/>
    <id>http://chenyin.top/机器学习与算法基础/20190325-d2ce.html</id>
    <published>2019-03-25T07:13:10.000Z</published>
    <updated>2019-04-08T07:31:45.680Z</updated>
    
    <content type="html"><![CDATA[<p>大数据包含了丰富的先验知识，即几乎包含了一切我们感兴趣的信息。但是数据量过大也会使我们在分析时感到茫然无措。特征过多使得我们不可能对单个特征进行详细解析，大部分时候我们是将所有特征当成一个整体进行考虑，或者分析特征之间的关系。对高维数据数据进行预处理是一种不错的选择，此时各种各样的<strong>降维</strong>浓缩技术应运而生。<a id="more"></a></p><p>降维的好处有哪些？</p><ol><li>减少数据维度，存储数据需要的空间也会减少（盘霸可忽略~）；</li><li>低维数据可以减少计算量，缩短模型训练时间；</li><li>很多算法在高维数据上的表现远远没有在低维数据上好；</li><li>去掉冗余特征（强相关特征），提高数据的质量；</li><li>有助于可视化，我们只能形象观察三维及以下的数据！</li></ol><h1 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h1><p>降维总是围绕着减少特征数进行的，根据对特征的操作可分为：</p><ul><li><strong>特征选择</strong>：保留原始特征集的子集，即选取部分原始特征；</li><li><strong>特征提取</strong>：构造不同于原始特征的新特征，新特征往往是原始特征的组合，替代原始特征表达原始数据想表达的信息。<br>特征提取是降维算法研究的核心内容。</li></ul><h1 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h1><p>特征选择只是对每个特征进行评估，去掉不重要的或者选出重要的：</p><ol><li>缺失值比率：按缺失值比率删除特征；</li><li>低方差滤波：删除方差小的特征；</li><li>高相关滤波：只保留高相关特征中的一个；</li><li>随机森林：计算每个特征的重要性；</li><li>前向特征选择：依次增加特征数检验模型性能；</li><li>反向特征消除：依次减少特征数检验模型性能。</li></ol><h1 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h1><p>特征提取才是降维思想的核心内容，降维算法家族枝繁叶茂，先做一个总体分类：<img src="" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;大数据包含了丰富的先验知识，即几乎包含了一切我们感兴趣的信息。但是数据量过大也会使我们在分析时感到茫然无措。特征过多使得我们不可能对单个特征进行详细解析，大部分时候我们是将所有特征当成一个整体进行考虑，或者分析特征之间的关系。对高维数据数据进行预处理是一种不错的选择，此时各种各样的&lt;strong&gt;降维&lt;/strong&gt;浓缩技术应运而生。
    
    </summary>
    
      <category term="机器学习与算法基础" scheme="http://chenyin.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/"/>
    
    
      <category term="降维" scheme="http://chenyin.top/tags/%E9%99%8D%E7%BB%B4/"/>
    
  </entry>
  
  <entry>
    <title>paper3 - RUV算法移除批次效应 (Davide Risso, 20140824)</title>
    <link href="http://chenyin.top/%E7%94%9F%E4%BF%A1%E5%B7%A5%E5%85%B7%E5%92%8C%E7%AE%97%E6%B3%95/20190322-afa7.html"/>
    <id>http://chenyin.top/生信工具和算法/20190322-afa7.html</id>
    <published>2019-03-22T01:37:34.000Z</published>
    <updated>2019-03-23T09:31:44.795Z</updated>
    
    <content type="html"><![CDATA[<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p> Gagnon-Bartsch et al.提出了RUV-2用来标准化<strong>连续的</strong>微阵列数据，移除不需要的变异。这里基于前面的方法进行扩展，用以标准化<strong>离散的</strong>RNA测序数据。</p><p> 对于表达矩阵（样本数 $n{\times}J$ 基因数）,构建<strong>泛化线性模型</strong> (Generalized Linear Model, GLM):<br>$$ \log{E[Y|W,X,O]}=W\alpha+X\beta+O $$<br><a id="more"></a><br>参数意义如下：</p><ul><li>$Y$ 是 $n{\times}J$ 的表达矩阵；</li><li>$W$ 是 $n{\times}k$ 与<strong>不需要的变异</strong>相关的<strong>多余变异相关矩阵</strong>（k是不需要的变异相关的变量的个数），$\alpha$ 是 $k{\times}J$ 的多余变异相关矩阵的系数（参数）；</li><li>$X$ 是 $n{\times}p$ 与<strong>感兴趣的变异</strong>相关的<strong>期望变异相关矩阵</strong>（p是感兴趣的变异相关的变量的个数），$\beta$ 是 $p{\times}J$ 的期望变异相关矩阵的系数（参数）；</li><li>$O$ 是一个 $n{\times}J$ 的矩阵，它可以置零，也可以包含其它的标准化过程（如<a href="https://en.wikipedia.org/wiki/Quantile_normalization" target="_blank" rel="noopener">UQ标准化</a>）。</li><li>矩阵 $X$ 是一个随机变量，是我们实验的测量值，是已知的（先验）。</li><li>矩阵 $W$ 是未观测的随机变量；$\alpha$、$\beta$、$k$ 都是未知参数。</li></ul><p>不同于先前的标准化方法，RUV可以使用GLM标准化技术同时标准化reads计数（$W\alpha$）和推断差异表达（$X\beta$）。标准化的计数也可以通过由原始计数对不需要的因子进行回归分析后求残差得到，但是直接从原始计数中移除不需要的因子（$W\alpha$）可能会损失掉 $X$ 的一部分。[<a href="">reference</a>]</p><p>同时估计 $W$, $\alpha$, $\beta$ 和 $k$ 是很难的。对于一个给定的 $k$ 值，我们尝试着用下面三种方法对$W$ 进行估计：</p><h2 id="1-基于阴性对照基因的RUVg"><a href="#1-基于阴性对照基因的RUVg" class="headerlink" title="1. 基于阴性对照基因的RUVg"></a>1. 基于阴性对照基因的RUVg</h2><ol><li>假设我们鉴定出了一个阴性对照基因 (negative control genes) 的集合（大小为 $J_c$），例如不差异表达的基因，对这个基因集合来说 $\beta_c=0$ 即 $\log{E[Y_c|W,X,O]}=W\alpha_c+O_c$，公式中的下标c将矩阵限制在了大小为 $J_c$ 的基因集合里。</li><li>定义 $Z=\log{Y}-O$，$Z^\ast$ 是 $Z$ 列向量中心化（$Z$ 的各个列向量均值都为0）的结果。</li><li>对 $Z_c^\ast$ 进行奇异值分解 (singular value decomposition, SVD) 即 $Z_c^\ast=U{\Lambda}V^T$。矩阵 $U$ 是 $n{\times}n$ 列正交矩阵，它的列向量是 $Z^\ast$ 的左奇异向量集；矩阵 $V$ 是 $J_c{\times}J_c$ 的列正交矩阵，它的列向量是 $Z^\ast$ 的右奇异向量集；$\Lambda$ 矩阵是由 $Z^\ast$ 的奇异值组成的非方形对角矩阵，大小为 $n{\times}J_c$。$Z^\ast$ 最少有 $\min{(n,J_c)}$ 个奇异值。对于一个给定的 $k$，通过 $\widehat{W\alpha_c}=U\Lambda_kV^T$ 估计 $W\alpha_c$，通过 $\hat{W}=U\Lambda_k$ 估计 $W$。$|lambda_k$ 是由 $\Lambda$ 导出的大小为 $n{\times}J_c$ 的非方形对角矩阵，保留 $\Lambda$ 中最大的 $k$ 个奇异值，将其它的奇异值置为0。</li><li>将 $\hat{W}$ 带入上面基于 $J$ 个基因构建的公式中，通过GLM回归估计 $\alpha$ 和 $\beta$。</li><li>（可选）将标准化的读段计数定义为 $Z$ 对 $\hat{W}$ 的普通最小二乘回归 (ordinary least squares, OLS) 的残差。 </li></ol><p>这是最基础的RUV-2的离散版本。其中的关键假设是我们能够找到这个阴性对照基因集合。然而，RUV-2已被证实对对照基因的选择十分敏感。我们因此考虑下面的两种方法：RUVr不需要阴性对照基因，RUVs对阴性对照基因选择的鲁棒性更强。</p><h2 id="2-基于残差的RUVr"><a href="#2-基于残差的RUVr" class="headerlink" title="2. 基于残差的RUVr"></a>2. 基于残差的RUVr</h2><ol><li>计算残差矩阵 $E(n{\times}J)$: 计数矩阵 $Y(n{\times}J)$ 关于感兴趣的协变量矩阵 $X(n{\times}J)$ 的初步GLM回归，例如异常值残差。这里用于回归计算的计数矩阵可以是未标准化的原始数据，也可以是经过其它标准化工具（例如UQ）处理过的数据。</li><li>对残差进行奇异值分解，即 $E=U{\Lambda}V^T$，通过 $\hat{W}=U\Lambda_k$ 估计 $w$。接下来的步骤与 <code>RUVg</code> 的第4、5步相同。</li></ol><h2 id="3-基于重复-阴性对照样本的RUVs"><a href="#3-基于重复-阴性对照样本的RUVs" class="headerlink" title="3. 基于重复/阴性对照样本的RUVs"></a>3. 基于重复/阴性对照样本的RUVs</h2><ol><li>假设在多个复制样本中具有生物学特征的（我们感兴趣的）某些协变量的表达量可看作恒定的，它们的计数差异与<code>RUVg</code>中的阴性对照基因一样，对我们后续的研究没有影响。现在假设有 $R$ 个复制组，$r(i){\in}{1,…,R}$ 表示样本 $i$ 所属的复制组；如果样本 $i$ 不属于任何一个复制组，则 $r(i)=0$。例如，对于SEQC数据集，样本A和样本B各自的64个<strong>复制本</strong>（$=4[\text{libraries}]{\times}2[\text{flow-cell}]{\times}8[\text{lanes}]$）分别组成了一个<strong>复制组</strong>。</li><li>对每一个复制本对应的计数矩阵进行<strong>列中心化</strong>处理，即矩阵各个列向量的均值都为0。去掉不属于预期复制组的样本，即筛选出 $n_d=\sum_i{I(r(i)\ne0)}$ 个样本对应的列中心化后的计数子矩阵 $Y_d(n_d{\times}J)$。 此时 $\log{E[Y_d|W,X,O]}=W_d\alpha+O_d$，对应的矩阵大小是 $(n_d{\times}J){\leftarrow}({n_d\times}k)({k\times}J)+(n_d{\times}J)$。</li><li>定义 $Z_d=\log{Y_d}-O_d$，$Z_d^\ast$ 是 $Z_d$ 列中心化的结果，$Z_d^\ast=U{\Lambda}V^T$。通过 $\hat{\alpha}=\Lambda_kV^T$（保留最大的 $k$ 个奇异值，$k{\le}\min{(n_d,J)}$）来估计 $\alpha$。</li><li>在所有 $n$ 个原始数据和 $J_c$ 个阴性对照基因上对 $Z_c$ 进行最小二乘回归（OLS）。估计讨厌因子 $W$：$\hat{W}=Z_c\hat\alpha_c^T(\hat\alpha_c\hat\alpha_c^T)^{-1}$。接下来的步骤与 <code>RUVg</code>的第4、5步相同。</li></ol><hr><h1 id="要点"><a href="#要点" class="headerlink" title="要点"></a>要点</h1><h2 id="两个数据集"><a href="#两个数据集" class="headerlink" title="两个数据集"></a>两个数据集</h2><ol><li><strong>SEQC data set</strong>: The third phase of the MicroArray Quality Control (MAQC) project, also known as the Sequencing Quality Control17 (SEQC) project, aims to assess the technical performance of high-throughput sequencing platforms by generating benchmarking data sets.</li><li><strong>Zebrafish (斑马鱼) data set</strong>: All procedures were conducted in compliance with US federal guidelines in an AAALAC-accredited facility and were approved by the UC Berkeley Office of Animal Care and Use. </li></ol><h2 id="两种讨厌因子"><a href="#两种讨厌因子" class="headerlink" title="两种讨厌因子"></a>两种讨厌因子</h2><p>本文分析了两种讨厌因子：<strong>library preparation</strong> &amp; <strong>flow-cell effects</strong>。</p><p><strong>flowcell</strong>：流动室，别称鞘流池、流动池，是流式细胞技术的基础关键部件。大概长这个样子：<br><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/flowcell-350x2332.jpg" width="100%"></p><p>作者用<strong>正交的主成分图</strong>展示了这两种讨厌因子：<br><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/2019-03-22_101808.jpg" width="100%"><span style="font-size:16px;color:gray">Scatterplot matrix of first three principal components (PC) for unnormalized counts (log scale, centered). The principal components are orthogonal linear combinations of the original 21,559-dimensional gene expression profiles, with successively maximal variance across the 128 samples, that is, the first principal component is the weighted average of the 21,559 gene expression measures that provides the most separation between the 128 samples. Each point corresponds to one of the 128 samples. The four sample A and the four sample B libraries are represented by different shades of blue and red, respectively (16 replicates per library). Circles and triangles represent samples sequenced in the first and second flow-cells, respectively. As expected for the SEQC data set, the first principal component is driven by the extreme biological difference between sample A and sample B. The second and third principal components clearly show library preparation effects (the samples cluster by shade) and, to a lesser extent, flow-cell effects reflecting differences in sequencing depths (within each shade, the samples cluster by shape).</span></p><h2 id="算法横向对比"><a href="#算法横向对比" class="headerlink" title="算法横向对比"></a>算法横向对比</h2><p><strong>上分位数标准化</strong> (Upper-quartile normalization, UQ)，UQ只能消除流细胞效应而对文库效应束手无策，RUV算法解决的就是如何消除不同文库的影响。</p><p><strong>局部加权回归散点平滑法</strong> (Locally Weighted Scatterplot Smoothing, LOWESS/LOESS)不能消除文库效应。</p><hr><h1 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h1><h2 id="ERCC-spike-in-controls"><a href="#ERCC-spike-in-controls" class="headerlink" title="ERCC spike-in controls"></a>ERCC spike-in controls</h2><p>ERCC 即 External RNA Controls Consortium，是斯坦福大学为了定制一套spike-in RNA而成立的专门性组织，主要的工作是设计了好用的spike-in RNA，方便microarray以及RNA-Seq进行内参定量。[<a href="https://jimb.stanford.edu/ercc/" target="_blank" rel="noopener">官方首页</a>]</p><p>RNA spike-in是一种数量和序列都已知的RNA转录本，用于校准RNA杂交实验（例如DNA微阵列实验、RT-qPCR、RNA测序等）的测量值。RNA spike-in作为对照组（控制组）探针，被设计成能与具有相应匹配序列的DNA分子结合，这个特异性结合的过程我们称之为<strong>杂交</strong>。在制备的过程中，已知数量的spike-in将与实验样本进行混合。spike-ins的杂交程度可以用来标准化样本RNA的测量值。[<a href="https://en.wikipedia.org/wiki/RNA_spike-in" target="_blank" rel="noopener">wiki</a>] [<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1797020" target="_blank" rel="noopener">reference</a>]</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;方法&quot;&gt;&lt;a href=&quot;#方法&quot; class=&quot;headerlink&quot; title=&quot;方法&quot;&gt;&lt;/a&gt;方法&lt;/h1&gt;&lt;p&gt; Gagnon-Bartsch et al.提出了RUV-2用来标准化&lt;strong&gt;连续的&lt;/strong&gt;微阵列数据，移除不需要的变异。这里基于前面的方法进行扩展，用以标准化&lt;strong&gt;离散的&lt;/strong&gt;RNA测序数据。&lt;/p&gt;
&lt;p&gt; 对于表达矩阵（样本数 $n{\times}J$ 基因数）,构建&lt;strong&gt;泛化线性模型&lt;/strong&gt; (Generalized Linear Model, GLM):&lt;br&gt;$$ \log{E[Y|W,X,O]}=W\alpha+X\beta+O $$&lt;br&gt;
    
    </summary>
    
      <category term="生信工具和算法" scheme="http://chenyin.top/categories/%E7%94%9F%E4%BF%A1%E5%B7%A5%E5%85%B7%E5%92%8C%E7%AE%97%E6%B3%95/"/>
    
    
  </entry>
  
  <entry>
    <title>批次效应（batch effect）</title>
    <link href="http://chenyin.top/%E7%94%9F%E4%BF%A1%E5%B7%A5%E5%85%B7%E5%92%8C%E7%AE%97%E6%B3%95/20190319-cca5.html"/>
    <id>http://chenyin.top/生信工具和算法/20190319-cca5.html</id>
    <published>2019-03-19T06:38:32.000Z</published>
    <updated>2019-03-23T09:32:34.774Z</updated>
    
    <content type="html"><![CDATA[<h1 id="一、定义"><a href="#一、定义" class="headerlink" title="一、定义"></a><span id="def">一、定义</span></h1><p>下面是大佬给出来的关于<strong>批次效应</strong>(batch effect)的定义：</p><blockquote><p>Batch effects are sub-groups of measurements that have qualitatively different behaviour across conditions and are unrelated to the biological or scientific variables in a study. For example, batch effects may occur if a subset of experiments was run on Monday and another set on Tuesday, if two technicians were responsible for different subsets of the experiments, or if two different lots of reagents, chips or instruments were used. <a href="https://www.nature.com/articles/nrg2825" target="_blank" rel="noopener">Leek et. al (2010)</a></p></blockquote><a id="more"></a><p>批次效应是测量结果中的一部分，它们因为实验条件的不同而具有不同的表现形式，并且与我们研究的变量没有半毛钱关系。一般批次效应可能在下述情形中出现：</p><ul><li>一个实验的不同部分在<strong>不同时间</strong>完成；</li><li>一个实验的不同部分由<strong>不同的人</strong>完成；</li><li>试剂用量不同、芯片不同、实验仪器不同；</li><li>将自己测的数据与从网上下载的数据混合使用；</li><li>……</li></ul><hr><h1 id="二、检测"><a href="#二、检测" class="headerlink" title="二、检测"></a>二、检测</h1><p>批次效应相关协变量已知时，直接聚类观察结果是否和相应协变量相关。<br>混合数据因为实验条件迥异，一般批次效应都很大。</p><p>以R为例，通过聚类检验是否存在批次效应。请先查看下面的<a href="#dataset">示例数据集</a>。<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># t() 转置函数</span></span><br><span class="line"><span class="comment"># dist() 距离函数：按照指定规则求行向量间的距离，因此要转置</span></span><br><span class="line">&gt; dist_mat &lt;- dist(t(edata))</span><br><span class="line">&gt; clustering &lt;- hclust(dist_mat) <span class="comment"># hclust 的输入结构与 dist 相同！</span></span><br><span class="line"><span class="comment"># 按照批次信息聚类</span></span><br><span class="line">&gt; plot(clustering, labels = pheno$batch)</span><br><span class="line"><span class="comment"># 按照是否是正常细胞聚类</span></span><br><span class="line">&gt; plot(clustering, labels = pheno$cancer)</span><br></pre></td></tr></table></figure></p><p>聚类结果如下：<br><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/ComBat-result1.png" width="50%"><br>左边的红色框框是正常细胞中混入的癌细胞，右边蓝色框框中是癌细胞中混入的正常细胞。</p><p>还有许多检验批次效应的的方法，这篇<a href="https://www.itl.nist.gov/div898/handbook/eda/section4/eda42a3.htm" target="_blank" rel="noopener">文章</a>给出了多种检验方式：</p><ul><li>图分析：双柱状图、QQ图、箱线图、块图、…</li><li>定量分析：F检验、双样本t检验、…</li></ul><hr><h1 id="三、处理"><a href="#三、处理" class="headerlink" title="三、处理"></a>三、处理</h1><p>实验条件允许的条件下，应该优化实验设计，将引起批次效应的协变量采样<strong>分散</strong>开来。例如，对于时间批次效应，实验的不同部分应该在各个时间内均匀采样。这叫“治病就治本”。</p><p>但是大多数情况下实验条件不允许，如果够幸运的话批次效应相关的协变量已经被记录下来了，此时对批次效应进行验证，然后使用统计模型过滤；如果十分不幸，批次效应相关的协变量没有被记录或者不明显，我们就需要借助相关工具猜一下哪个变量可能造成了批次效应，然后使用统计模型过滤。前者叫<strong>参数化方法</strong>，后者叫<strong>非参数化方法</strong>。</p><h2 id="1-导入示例数据集"><a href="#1-导入示例数据集" class="headerlink" title="1.导入示例数据集"></a><span id="dataset">1.导入示例数据集</span></h2><h3 id="bladderbatch包"><a href="#bladderbatch包" class="headerlink" title="bladderbatch包"></a>bladderbatch包</h3><p><code>bladderbatch</code>包包含了一项<a href="https://www.ncbi.nlm.nih.gov/pubmed/15173019" target="_blank" rel="noopener">膀胱癌研究</a>中相关的57个样本的基因表达数据，这些数据已经使用RMA标准化，并且已经按照<a href="https://www.ncbi.nlm.nih.gov/pubmed/20838408" target="_blank" rel="noopener">相关协议</a>进行了预处理。</p><p>另外阅读R文档我们发现：</p><ul><li><code>eSet</code>是一个包含高通量实验元数据的一个类，它不能直接被实例化。</li><li><code>pData</code>方法在类<code>eSet</code>中被定义，它的作用是访问数据的元数据（注释信息）。</li><li><code>ExpressionSet</code>继承自<code>eSet</code>，同样是一个高通量测序数据的容器，由&gt; * <code>biobase</code>包引入，封装了<strong>表达矩阵</strong>和<strong>样本分组信息</strong>。表达矩阵存储在<code>exprs</code>中。</li></ul><p><code>bladderbatch</code>数据集是（类似）<code>ExpressionSet</code>类型，我们可以使用<code>pData()</code>加载元数据，使用<code>exprs()</code>加载表达谱数据。<br><code>bladderbatch</code>数据集用来演示如何校正批次效应。</p><h3 id="下载和加载数据集"><a href="#下载和加载数据集" class="headerlink" title="下载和加载数据集"></a>下载和加载数据集</h3><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 1.安装并加载数据集</span></span><br><span class="line">&gt; BiocInstaller::biocLite(<span class="string">"bladderbatch"</span>)</span><br><span class="line">&gt; <span class="keyword">library</span>(bladderbatch) <span class="comment"># 或者 library("bladderbatch", character.only=TRUE)</span></span><br><span class="line"><span class="comment">## 2.查看当前可用数据集</span></span><br><span class="line">&gt; data()</span><br><span class="line"><span class="comment">## 3.检查是否有如下信息</span></span><br><span class="line">Data sets <span class="keyword">in</span> package ‘bladderbatch’:</span><br><span class="line">bladderEset (bladderdata)           Bladder Gene Expression Data Illustrating Batch Effects</span><br><span class="line"><span class="comment">## 加载数据集</span></span><br><span class="line">&gt; data(bladderdata) <span class="comment"># 实际加载进来的数据集名字叫做 bladderEset !</span></span><br><span class="line">&gt; pheno &lt;- pData(bladderEset) <span class="comment"># 使用 pData 加载元数据/注释信息</span></span><br><span class="line">&gt; edata &lt;- exprs(bladderEset) <span class="comment"># 使用 exprs 加载数据</span></span><br></pre></td></tr></table></figure><p><code>pheno</code>如下所示：<br><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/ComBat-pheno.png" width="20%"><br>样本的批次信息存储作为元数据存储在<code>pheno$batch</code>中（R中使用<code>$</code>访问对象的属性）。</p><p><code>edata</code>如下所示：<br><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/ComBat-edata.png" width="50%"><br>一列表示一个样本（细胞），后面求距离需要转置。</p><hr><h2 id="2-R中的sva包"><a href="#2-R中的sva包" class="headerlink" title="2.R中的sva包"></a>2.R中的sva包</h2><p><code>sva</code>用于移除高通量测序数据中的<a href="#def"><strong>批次效应</strong></a>以及其它无关变量的影响。</p><p><code>sva</code>包含用于标识和构建高维数据集（例如基因表达、RNA测序/甲基化/脑成像数据等可以直接进行后续分析的数据）<strong>代理变量</strong>的函数。代理变量是直接从高维数据构建的协变量，可以在后续分析中用于调整未知的、未建模的或潜在的噪音源。</p><blockquote><p><strong>代理变量（surrogate/proxy variable）</strong>: A variable that can be measured (or is easy to measure) that is used in place of one that cannot be measured (or is difficult to measure). For example, whereas it may be difficult to assess the wealth of a household, it is relatively easy to assess the value of a house. See also proxy variable. (from <a href="http://www.oxfordreference.com/view/10.1093/oi/authority.20110803100544210" target="_blank" rel="noopener">Oxford Reference</a>)<br><strong>代理变量分析（Surrogate Variable Analysis）</strong>：<a href="https://digital.lib.washington.edu/researchworks/handle/1773/9586" target="_blank" rel="noopener">Click here</a></p></blockquote><p><code>sva</code>从三个方面消除人为设计造成的影响：</p><ol><li>为未知变异源构造代理变量；(Leek and Storey <a href="https://www.ncbi.nlm.nih.gov/pubmed/17907809" target="_blank" rel="noopener">2007 PLoS Genetics</a>, <a href="https://www.ncbi.nlm.nih.gov/pubmed/20941797" target="_blank" rel="noopener">2011 Pharm Stat.</a>)</li><li>使用ComBat直接移除已知的批次效应；<a href="https://academic.oup.com/biostatistics/article/8/1/118/252073" target="_blank" rel="noopener">(Johnson et al. 2007 Biostatistics)</a></li><li>使用已知的控制探针(known control probes)移除批次效应；<a href="https://www.biorxiv.org/content/10.1101/006585v2" target="_blank" rel="noopener">(Leek 2014 biorXiv)</a><br>移除批次效应和使用代理变量可以减少依赖性，稳定错误率估计值，提高重现性。</li></ol><p>查看<code>sva</code><a href="http://127.0.0.1:28090/library/sva/doc/sva.pdf" target="_blank" rel="noopener">在线文档</a>。</p><h3 id="gt-已记录批次信息"><a href="#gt-已记录批次信息" class="headerlink" title="&gt; 已记录批次信息"></a>&gt; 已记录批次信息</h3><p>当<strong>批次协变量</strong>已知时（即每个样本分属于哪一个批次记录在数据集的元数据中），可以使用<code>sva</code>的<code>ComBat</code>校正<strong>批次效应</strong>。<br><code>ComBat</code>使用参数（parametric）或者非参数（non-parametric）的<strong>经验贝叶斯框架</strong>（Empirical Bayes Frameworks）进行批次效应的校正。</p><p>先看<code>ComBat</code>的用法：摘自<a href="https://www.rdocumentation.org/packages/sva/versions/3.20.0/topics/ComBat" target="_blank" rel="noopener">官方文档</a><br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; ComBat(dat, batch, mod=<span class="literal">NULL</span>, par.prior = <span class="literal">TRUE</span>, prior.plots = <span class="literal">FALSE</span>)</span><br><span class="line"><span class="comment"># dat: 基因组测量矩阵（探针维度 X 样本数），探针维度例如marker数、基因数.....，例如表达谱矩阵</span></span><br><span class="line"><span class="comment"># batch: 批次协变量，只能传入一个批次协变量！</span></span><br><span class="line"><span class="comment"># mod: 这是一个模式矩阵，里面包含了我们感兴趣的变量！</span></span><br><span class="line"><span class="comment"># par.prior: 基于参数/非参数，默认为基于参数</span></span><br></pre></td></tr></table></figure></p><p>有了背景知识我们就可以进行膀胱癌数据的批次校正：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; pheno$hasCancer &lt;- pheno$cancer == <span class="string">"Cancer"</span></span><br><span class="line"><span class="comment"># 或者 &gt; pheno$hasCancer &lt;- as.numeric(pheno$cancer == "Cancer")</span></span><br><span class="line">&gt; model &lt;- model.matrix(~hasCancer, data=pheno)</span><br><span class="line">&gt; combat_edata &lt;- ComBat(dat = edata, batch = pheno$batch, mod = model)</span><br><span class="line"><span class="comment"># 这里的 mod 参数就比较有意思了，它记录的是我们感兴趣的变量。因为初次接触R只能肤浅理解一下。</span></span><br><span class="line"><span class="comment"># 它应该是一个我们期望样本能被正确聚类所依据的协变量，它总是数值型变量</span></span><br></pre></td></tr></table></figure></p><p><code>model.matrix(...)</code>的详细解释见<a href="/R/20190319-1548.html">这里</a>。</p><p>画图：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; dist_mat_combat &lt;- dist(t(combat_edata))</span><br><span class="line">&gt; clustering_combat &lt;- hclust(dist_mat_combat, method = <span class="string">"complete"</span>)</span><br><span class="line">&gt; plot(clustering, labels = pheno$batch)</span><br><span class="line">&gt; plot(clustering, labels = pheno$cancer))</span><br></pre></td></tr></table></figure></p><p>我们发现批次效应被移除了：<br><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/ComBat-result2.png" width="50%"></p><h3 id="gt-没有记录批次信息"><a href="#gt-没有记录批次信息" class="headerlink" title="&gt; 没有记录批次信息"></a>&gt; 没有记录批次信息</h3><p><a href="http://master.bioconductor.org/packages/release/workflows/vignettes/rnaseqGene/inst/doc/rnaseqGene.html#removing-hidden-batch-effects" target="_blank" rel="noopener">看这里</a></p><hr><h2 id="3-R中的ber包"><a href="#3-R中的ber包" class="headerlink" title="3.R中的ber包"></a>3.R中的ber包</h2><p>ber的全称就是batch effects removal，使用<code>&gt; install.packages(&quot;ber&quot;)</code>安装ber包，查看<a href="https://cran.r-project.org/web/packages/ber/ber.pdf" target="_blank" rel="noopener">用户手册</a>。</p><p>这个包里有6个函数，它们的作用就是校正<strong>微阵列标准数据</strong>中的批次效应。标准数据指的是：输入矩阵每一行代表独立的样本，每一列代表基因；批次信息作为已知的<strong>分类变量</strong>；期望变量可以大大提高批次效应校正的效率。</p><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td><code>berr(Y, b, covariates = NULL)</code></td><td>using a two-stage regression approach <a href="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/2019031901.pdf" target="_blank" rel="noopener">(M. Giordan. February 2013)</a></td></tr><tr><td><code>ber_bg(Y, b, covariates = NULL,partial=TRUE,nSim=150)</code></td><td>using a two-stage regression approach and bagging <a href="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/2019031901.pdf" target="_blank" rel="noopener">(M. Giordan. February 2013)</a></td></tr><tr><td><code>combat_p(Y, b, covariates = NULL, prior.plots=T)</code></td><td>using a parametric empirical Bayes approach <a href="https://www.ncbi.nlm.nih.gov/pubmed/16632515" target="_blank" rel="noopener">(n Johnson et al. 2007)</a></td></tr><tr><td><code>combat_np(Y, b, covariates = NULL)</code></td><td>using a non-parametric empirical Bayes approach <a href="https://www.ncbi.nlm.nih.gov/pubmed/16632515" target="_blank" rel="noopener">(n Johnson et al. 2007)</a></td></tr><tr><td><code>mean_centering(Y, b)</code></td><td>using the means of the batches</td></tr><tr><td><code>standardization(Y, b)</code></td><td>using the means and the standard deviations of the batches</td></tr></tbody></table><p>上表中的：</p><ul><li><code>Y</code>是输入矩阵（样本数 $n{\times}g$ 探针数）</li><li><code>b</code>是 $n$ 维<strong>分类1向量</strong>，每个分量对应着每个样本的批次信息</li><li><code>covariates</code>是一个 $n$ 行的<code>data.frame</code>实例</li></ul><p>上面的6个函数都需要指定<code>b</code>，所以它们都是用来处理<strong>批次信息被记录</strong>的情形的，对于启发性的校正貌似没提出解决方案。</p><hr><h2 id="4-R中的RUVSeq包"><a href="#4-R中的RUVSeq包" class="headerlink" title="4.R中的RUVSeq包"></a>4.R中的RUVSeq包</h2><p>RUVSeq means <em>Remove Unwanted Variation from RNA-Seq Data</em>, which shows us how to conduct a differential expression (DE) analysis that controls for “unwanted variation”, e.g., batch, library preparation, and other nuisance effects, using the between-sample normalization methods proposed in <a href="https://www.nature.com/articles/nbt.2931" target="_blank" rel="noopener">Risso et al. (2014)</a>.</p><p>RUV算法基本原理参考<a href="/Bioinformatics/20190322-afa7.html">这里</a>，原文在<a href="https://www.nature.com/articles/nbt.2931" target="_blank" rel="noopener">这里</a>。</p><hr><h2 id="5-R中的BatchQC包"><a href="#5-R中的BatchQC包" class="headerlink" title="5. R中的BatchQC包"></a>5. R中的BatchQC包</h2><p><a href="https://bioconductor.org/packages/release/bioc/html/BatchQC.html" target="_blank" rel="noopener">BatchQC工具</a></p><hr><h1 id="四、FAQ"><a href="#四、FAQ" class="headerlink" title="四、FAQ"></a>四、FAQ</h1><ol><li><strong>标准化（normalization）可以消除批次效应吗？</strong> 只能缓解，不能消除。</li></ol><hr><h1 id="五、其它资料"><a href="#五、其它资料" class="headerlink" title="五、其它资料"></a>五、其它资料</h1><p>Stanford大学MOOC公开课讲义：<a href="http://genomicsclass.github.io/book/" target="_blank" rel="noopener">PH525x series - Biomedical Data Science</a></p><p><a href="https://bioinformatics.mdanderson.org/public-software/tcga-batch-effects/" target="_blank" rel="noopener">TCGA Batch Effects Viewer</a></p><p>From BioMedSearch: <a href="http://www.biomedsearch.com/nih/Removing-batch-effects-in-analysis/21386892.html" target="_blank" rel="noopener">Removing batch effects in analysis of expression microarray data: an evaluation of six batch adjustment methods.</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;一、定义&quot;&gt;&lt;a href=&quot;#一、定义&quot; class=&quot;headerlink&quot; title=&quot;一、定义&quot;&gt;&lt;/a&gt;&lt;span id=&quot;def&quot;&gt;一、定义&lt;/span&gt;&lt;/h1&gt;&lt;p&gt;下面是大佬给出来的关于&lt;strong&gt;批次效应&lt;/strong&gt;(batch effect)的定义：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Batch effects are sub-groups of measurements that have qualitatively different behaviour across conditions and are unrelated to the biological or scientific variables in a study. For example, batch effects may occur if a subset of experiments was run on Monday and another set on Tuesday, if two technicians were responsible for different subsets of the experiments, or if two different lots of reagents, chips or instruments were used. &lt;a href=&quot;https://www.nature.com/articles/nrg2825&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Leek et. al (2010)&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="生信工具和算法" scheme="http://chenyin.top/categories/%E7%94%9F%E4%BF%A1%E5%B7%A5%E5%85%B7%E5%92%8C%E7%AE%97%E6%B3%95/"/>
    
    
  </entry>
  
  <entry>
    <title>model.matrix(...)</title>
    <link href="http://chenyin.top/R%E7%BB%9F%E8%AE%A1%E8%AF%AD%E8%A8%80/20190319-1548.html"/>
    <id>http://chenyin.top/R统计语言/20190319-1548.html</id>
    <published>2019-03-19T03:34:18.000Z</published>
    <updated>2019-03-25T14:56:32.403Z</updated>
    
    <content type="html"><![CDATA[<p>R中的模型矩阵函数。<a id="more"></a></p><h1 id="分类变量"><a href="#分类变量" class="headerlink" title="分类变量"></a>分类变量</h1><p><strong>分类变量</strong>（Factors）：R中用来存储分类数据的类别信息。<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt; f = factor(c(<span class="string">'a'</span>,<span class="string">'b'</span>,<span class="string">'a'</span>,<span class="string">'c'</span>))</span><br><span class="line"><span class="comment"># 检查变量是否是分类变量（因子）</span></span><br><span class="line">&gt; class(f)</span><br><span class="line">[<span class="number">1</span>] <span class="string">"factor"</span></span><br><span class="line"><span class="comment"># 查看分类变量中有哪些类别</span></span><br><span class="line">&gt; levels(f)</span><br><span class="line">[<span class="number">1</span>] <span class="string">"a"</span> <span class="string">"b"</span> <span class="string">"c"</span></span><br><span class="line"><span class="comment"># 查看分类变量中有几类</span></span><br><span class="line">&gt; nlevels(f)</span><br><span class="line">[<span class="number">1</span>] <span class="number">3</span></span><br></pre></td></tr></table></figure></p><h1 id="哑变量"><a href="#哑变量" class="headerlink" title="哑变量"></a>哑变量</h1><p><strong>虚拟变量</strong>/<strong>哑变量</strong>（dummy variable）：量化非数值类型的变量，通常取0/1。例如，衡量一个人的性别：男 -&gt; 1，女 -&gt; 0。</p><h1 id="解释变量"><a href="#解释变量" class="headerlink" title="解释变量"></a>解释变量</h1><p><strong>解释变量</strong>（explanatory variable）：单纯从数理角度来看，解释变量等同于控制变量/自变量，与之相对的是<strong>被解释变量</strong>（反应变量/因变量）。<a href="http://blog.sciencenet.cn/blog-334577-426759.html" target="_blank" rel="noopener">REF</a></p><h1 id="设计矩阵"><a href="#设计矩阵" class="headerlink" title="设计矩阵"></a>设计矩阵</h1><p><strong>设计矩阵</strong>（design matrix）：又叫<strong>模型矩阵</strong>（model matrix）或者<strong>回归矩阵</strong>（regressor matrix）。由解释变量值组成的矩阵：一行代表一个独立的观测对象（样本），一列代表对应的变量（特征值、元数据），通常记为$X$。简单理解，就是我们所说的<strong>输入矩阵</strong>，可以是元数据的，也可以是数据的。</p><h1 id="model-matrix-…"><a href="#model-matrix-…" class="headerlink" title="model.matrix(…)"></a>model.matrix(…)</h1><p>定义：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># S3 method for default </span></span><br><span class="line">model.matrix(object, data = environment(object), contrasts.arg = <span class="literal">NULL</span>, xlev = <span class="literal">NULL</span>, …)</span><br><span class="line"><span class="comment"># 函数依据 object 创建设计矩阵，矩阵的创建必须借助于数据集 data</span></span><br><span class="line"><span class="comment"># data 必须能提供与 object 相同名字的变量！</span></span><br></pre></td></tr></table></figure></p><p>以膀胱癌去批次效应为例，元数据形式如下<br><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/model.matrix.pheno.png" alt="model.matrix.pheno"></p><p>下面是部分列处理后的结果：<br><figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">&gt; model &lt;- model.matrix(~batch, data = pheno)</span><br><span class="line">                  (Intercept)batch</span><br><span class="line">GSM71019.CEL           <span class="number">1</span>     <span class="number">3</span></span><br><span class="line">GSM71020.CEL           <span class="number">1</span>     <span class="number">2</span></span><br><span class="line"><span class="comment"># pheno$batch 是数值型变量，相当于提取列</span></span><br><span class="line"><span class="comment"># 此时新的变量名仍然是 batch</span></span><br><span class="line"><span class="comment">#---------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">&gt;model &lt;-  model.matrix(~cancer, data = pheno)</span><br><span class="line">             (Intercept) cancerCancer cancerNormal</span><br><span class="line">GSM71019.CEL           <span class="number">1</span>            <span class="number">0</span>            <span class="number">1</span></span><br><span class="line">GSM71020.CEL           <span class="number">1</span>            <span class="number">0</span>            <span class="number">1</span></span><br><span class="line"><span class="comment"># pheno$cancer 被处理成分类变量，每一类将单独作为列（哑变量），取值为0/1</span></span><br><span class="line"><span class="comment"># 此时新的变量名为 cancerCancer 和 cancerNormal</span></span><br><span class="line"><span class="comment">#---------------------------------------------------------------------</span></span><br><span class="line"></span><br><span class="line">&gt; model &lt;- model.matrix(~cancer==<span class="string">"Cancer"</span>, data = pheno)</span><br><span class="line">             (Intercept) cancer == <span class="string">"Cancer"</span><span class="literal">TRUE</span></span><br><span class="line">GSM71019.CEL           <span class="number">1</span>                            <span class="number">0</span></span><br><span class="line">GSM71020.CEL           <span class="number">1</span>                            <span class="number">0</span></span><br><span class="line"><span class="comment"># cancer=="Cancer" 是一个 logical 类型</span></span><br><span class="line"><span class="comment"># 这种写法极不优雅！我们应该先定好名字</span></span><br><span class="line">&gt; pheno$hasCancer &lt;- pheno$cancer == <span class="string">"Cancer"</span></span><br><span class="line">&gt; model &lt;- model.matrix(~hasCancer, data=pheno)</span><br><span class="line">             (Intercept) hasCancer</span><br><span class="line">GSM71019.CEL           <span class="number">1</span>         <span class="number">0</span></span><br><span class="line">GSM71020.CEL           <span class="number">1</span>         <span class="number">0</span></span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;R中的模型矩阵函数。
    
    </summary>
    
      <category term="R统计语言" scheme="http://chenyin.top/categories/R%E7%BB%9F%E8%AE%A1%E8%AF%AD%E8%A8%80/"/>
    
    
  </entry>
  
  <entry>
    <title>生信分析工具-SCENIC</title>
    <link href="http://chenyin.top/%E7%94%9F%E4%BF%A1%E5%B7%A5%E5%85%B7%E5%92%8C%E7%AE%97%E6%B3%95/20190315-94a8.html"/>
    <id>http://chenyin.top/生信工具和算法/20190315-94a8.html</id>
    <published>2019-03-15T10:53:18.000Z</published>
    <updated>2019-03-25T14:57:21.316Z</updated>
    
    <content type="html"><![CDATA[<p><strong>SCENIC: Single-cell regulatory network inference and clustering</strong></p><p>基于regulon(TF-&gt;targets)构建GRNs，基于GRNs可以进行细胞聚类。</p><p>与其说是算法，不如说SCENIC是组合算法的一个流程。如下图所示：</p><p><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/scenic-01.png" alt=""><br><a id="more"></a></p><h1 id="1-基因数据过滤"><a href="#1-基因数据过滤" class="headerlink" title="1. 基因数据过滤"></a>1. 基因数据过滤</h1><p>共表达分析之前需要对基因数据进行过滤，本文使用如下两个方法：</p><p>1.根据每个基因的reads数目移除可信度低或者将产生较大噪声的基因。reads数目的阈值与数据集的大小有关，以下是原文表述：3 UMI counts (slightly over the median of the nonzero values) multiplied by 1% of the number of cells in the dataset (e.g. in mouse brain: 3 UMI counts x 30 (1% of cells) = minimum 90 counts per gene).</p><p>2.根据可检测到某个基因的细胞数目过滤掉只在一个细胞或者极少量细胞中表达的基因，细胞数目的阈值设定参考原文：set a percentage lower than the smallest population of cells to be detected. For example, since microglia cells represent approximately 3% of the total cells in the dataset, we used a detection threshold of at least 1% of the cells.</p><h1 id="2-共表达分析"><a href="#2-共表达分析" class="headerlink" title="2. 共表达分析"></a>2. 共表达分析</h1><p>仅仅借助<strong>共表达分析</strong>(co-expression analysis)(GENIE3或者GRNBoost)得到regulons的表达情况（GRNs）。一个regulon由一个TF和它调控的靶基因组成。当数据集非常大时GENIE3的运行速度将会变得非常慢，此时使用GRNBoost替换GENIE3能大大加快计算速度。</p><p>但是，共表达分析存在许多假阳性结果，我们需要找到这些实际上不存在的TF-靶基因配对，因此需要下一步的基序富集分析。</p><h2 id="GENIE3"><a href="#GENIE3" class="headerlink" title="GENIE3"></a>GENIE3</h2><p>GENIE3的核心算法是<strong>随机森林回归模型</strong>。随机森林能够处理非线性共表达关系。针对不同的TF训练不同的模型，这些模型用于计算相应TF的权重，这些权重可以用来衡量它与靶基因共表达的强度。</p><p>输入：一个基因表达矩阵，矩阵的每一列代表一个细胞的不同基因，每一行代表一个基因在不同细胞里的表达量。矩阵的元素可以是UMI计数，也可以是其它指标，例如TPM (Transcripts Per Million)、FPKM/RPKM等等。输入矩阵应避免进行标准化或归一化处理，这样会人为的引入多余的协方差。</p><p>输出：一张三列表，分别代表TF、靶基因、权重（TF靶向目标基因的可信度）</p><h2 id="GRNBoost"><a href="#GRNBoost" class="headerlink" title="GRNBoost"></a>GRNBoost</h2><blockquote><p>Spark <strong>RDD</strong>：Risilient Distributed Datasets 弹性分布式数据库<br><strong>广播变量</strong>(Broadcast Variable)：将只读变量广播到各个节点以供读取，避免变量在任务间进行传递。变量被广播之后应避免被修改。</p></blockquote><p>GRNBoost作为GENIE3在大数据集下的替代方案，它仍然接受GENIE3的基本思想：仅从基因表达数据中推断GRNs。</p><p>算法方面，GRNBoost使用了XGBoost库中的GBM (Gradient Boosting Machines)。GBM是一种结合多种弱学习器、以提升学习作为基本策略的集成学习方法。相对于随机森林，GBM使用了bagging自助聚合进行模型的平均以提高回归准确度。</p><p>然而，GRNBoost的主要贡献是基于Spark实现了多回归并行计算。<br>软件输入是<strong>基因表达向量</strong>（一系列基因和一个转录因子表达量组成的向量？）。<br>GRNBoost首先将基因表达向量分发给集群的各个节点，然后构建一个基于表达数据全集的预测矩阵。<br>然后使用<strong>广播变量</strong>（Broadcast Variable）将这个预测矩阵广播到各个节点，接下来进行Map/Reduce分布式计算。</p><p><strong>Map阶段</strong>：基于基因表达向量使用预测器训练XGBoost回归模型。基于训练的模型，TF和靶基因的靶向强度将以网络的边的形式呈现出来。</p><p><strong>Reduce阶段</strong>：整合所有的边形成最终的GRNs。</p><h1 id="3-基序富集分析"><a href="#3-基序富集分析" class="headerlink" title="3. 基序富集分析"></a>3. 基序富集分析</h1><p><strong>基序富集分析</strong>(motif enrichment analysis)使用的工具是RcisTarget，它能找到共表达分析的假阳性结果。删除这些假阳性结果就能得到正确的GRNs (Gene Regulatory Networks)。</p><p>RcisTarget 是 i-cisTarget 和 iRegulon 基序富集框架的 R/Bioconductor 实现。</p><p>主要分为两个步骤：</p><ol><li>选择在基因的转录起始位点（TSS）附近明显高表达的DNA基序<br>This is achieved by applying a recovery-based method on a database that contains genome-wide cross-species rankings for each motif. 实现方法：在基序全基因组跨物种排名数据库上使用recovery方法<br>保留那些可以注释到TF并且标准富集分数(Normalized Enrichment Score, NES)大于3.0的基序<br>2.对于每个基序和基因集，RcisTarget预测候选靶基因（如在基因集中排列在前缘以上的基因）<br>方法详情见引用[32]，此方法在i-cisTarget&amp;iRegulon中均有实现，因此使用RcisTarget得到的结果与i-cisTarget&amp;iRegulon的结果一致</li></ol><p>为了构建最终的调控子，我们将每个有基序富集的TF模块预测的靶基因进行归并。<br>上面针对的是正调控，对于抑制，仍然可以对负相关的TF模块做相同的处理；但是我们的分析中，这类模块较少。<br>基于上述事实，本实验之研究正相关，不研究负相关<br>本文使用的数据集：the “18k motif collection” from iRegulon (gene-based motif rankings) for human and mouse<br>TSS搜索空间：10kb around the TSS or 500bp upstream the TSS</p><h1 id="4-AUCell打分"><a href="#4-AUCell打分" class="headerlink" title="4. AUCell打分"></a>4. AUCell打分</h1><p>The relative scores of each regulon across the cells allow identifying which cells have a significantly high sub-network activity<br>细胞的调节子打分容许我们识别哪些细胞具有明显的高子网络活性？？？结果是一个二进制的活性矩阵，可用于下游分析<br>——对此矩阵的聚类可用于细胞类型或者细胞状态的识别，基于调控子网络的活性共享。<br>对抗dropouts增强鲁棒性：对调节子整体进行打分，而不是针对特定的转录因子或者单个基因。</p><p>基于单细胞测序数据，从活化的GRNs中鉴定细胞<br>输入是一个基因集，输出为每个细胞中基因集的活性（AUC指标）<br>在SCENIC中，这些基因集表现为regulons，每个调控子由一个TF和它对应的靶基因组成<br>AUCell calculates the enrichment of the regulon as an area under the recovery curve (AUC) across the ranking of all genes in a particular cell, whereby genes are ranked by their expression value.<br>将AUC区域面积作为regulon的富集量，该区域包含了特定细胞中所有基因的排序。<br>This method is therefore independent of the gene expression units and the normalization procedure.<br>因为是在单个细胞上进行检验，因此很容易可以应用到大数据集</p><p><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/scenic-02.png" alt=""></p><p>——AUCell用来估计每个细胞中每个regulon的活性，通过计算恢复曲线下的面积，整合了每个regulon里所有排列的基因的信息<br>——AUC打分（上面计算出来的）通过设定阈值构建Regulon Activity Matrix，用来判定哪些细胞里的regulon处于on状态<br>——左图横坐标是一个regulon的靶基因的排列，纵坐标是从输入数据集中数出来的基因数目<br>然后，AUCell使用“曲线下面积”(AUC)计算输入基因集中的一个关键子集是否在每个细胞的排名顶部富集。<br>AUC表示表达基因在特征中的比例以及相对于细胞内其他基因的相对表达值<br>这一部的输出是一个矩阵：每一个细胞的每一个基因集的AUC分数<br>使用细胞中的一系列regulon的AUC值进行细胞的聚类，或者使用处理过的二值矩阵<br>——二值矩阵：自动 or 手动<br>——下图是AUC分布的几个例子</p><h1 id="5-基于GRNs的细胞聚类"><a href="#5-基于GRNs的细胞聚类" class="headerlink" title="5. 基于GRNs的细胞聚类"></a>5. 基于GRNs的细胞聚类</h1><p>AUC activity matrix：每个细胞中每个regulon的AUC值，连续值<br>regulon activity matrix：上面矩阵二值化的结果，01矩阵<br>可视化：主要用t-SNE、层次聚类的热图<br>探究结果的其他可选项<br>—— t-SNE的高密度区域 =&gt; 最可能的稳定状态<br>—— 鉴定key regulators<br>—— 基于数据库注释了解细胞属性<br>—— GO terms (regulon内的基因富集分析)</p><blockquote><p>操纵子（operon）：包含了操纵基因的核苷酸序列，被某个启动子控制，对应一组受操纵基因调控的基因<br>调节子（regulon）：对应受某个起调节作用的蛋白质调节的一组基因<br>刺激子（stimulon）：对应某类起调节作用的细胞调节的一组基因</p></blockquote><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><p>Nat Methods. 2017 Nov;14(11):1083-1086. doi: 10.1038/nmeth.4463. Epub 2017 Oct 9.<br><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5937676" target="_blank" rel="noopener">SCENIC: Single-cell regulatory network inference and clustering</a><br>Aibar S1,2, González-Blas CB1,2, Moerman T3,4, Huynh-Thu VA5, Imrichova H1,2, Hulselmans G1,2, Rambow F6,7, Marine JC6,7, Geurts P5, Aerts J3,4, van den Oord J8, Atak ZK1,2, Wouters J1,2,8, Aerts S1,2.</p><p><a href="http://scenic.aertslab.org" target="_blank" rel="noopener">&gt;&gt;&gt; SCENIC</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;SCENIC: Single-cell regulatory network inference and clustering&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;基于regulon(TF-&amp;gt;targets)构建GRNs，基于GRNs可以进行细胞聚类。&lt;/p&gt;
&lt;p&gt;与其说是算法，不如说SCENIC是组合算法的一个流程。如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/scenic-01.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="生信工具和算法" scheme="http://chenyin.top/categories/%E7%94%9F%E4%BF%A1%E5%B7%A5%E5%85%B7%E5%92%8C%E7%AE%97%E6%B3%95/"/>
    
    
  </entry>
  
  <entry>
    <title>生信分析工具-RaceID2+StemID</title>
    <link href="http://chenyin.top/%E7%94%9F%E4%BF%A1%E5%B7%A5%E5%85%B7%E5%92%8C%E7%AE%97%E6%B3%95/20190315-98e6.html"/>
    <id>http://chenyin.top/生信工具和算法/20190315-98e6.html</id>
    <published>2019-03-15T08:17:11.000Z</published>
    <updated>2019-03-25T14:57:57.330Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>数据分析时要处理的噪声不仅来自实验误差和测量误差，基因表达和少量mRNA的扩增都会产生一定的噪声。其中来自生物过程的噪声可以通过大量测序来缓和。</p><p>如果根据某一时刻的转录表达情况推断细胞系谱结构一直是一个严峻的挑战。作者肯定了<a href="/生物信息学/20190315-643b.html">Wanderlust算法</a>的设计思想，但是同时对其设计的拓扑结构的合理性表示怀疑，并提出了自己的解决方案。</p><p>RaceID2算法旨在：基于单细胞转录组数据，通过聚类鉴定出干细胞</p><p>StemID算法旨在：利用RaceID2的聚类结果，构建系谱树</p><a id="more"></a><h1 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h1><p>算法在小肠的Lgr5+细胞、骨髓造血干细胞上学习，在人类胰腺多能干细胞上测试。Lgr5+小鼠肠道干细胞群的分化过程研究已经发表，作为算法学习的基础数据集。</p><h2 id="RaceID"><a href="#RaceID" class="headerlink" title="RaceID"></a>RaceID</h2><p><a href="https://www.nature.com/articles/nature14966" target="_blank" rel="noopener">此处嘀向作者2015年发表的论文</a></p><h2 id="RaceID2"><a href="#RaceID2" class="headerlink" title="RaceID2"></a>RaceID2</h2><p>作者对自己已经发表的RaceID算法进行优化：RaceID使用K-means进行聚类，因此求所有样本平均值的做法使得RaceID对异常值十分敏感，同时RaceID使用<strong>间隔统计量</strong>（Gap Statistics, GS）确定分类个数；但是作者认为这种方法并不理想，因此在RaceID2中改用K-medoids方法聚类，并且依据类内散布饱和临界值为依据确定分类个数。K-medoids聚类方法使用类似于中位数的方法确定聚类中心，与K-means不同，它的聚类中心始终产生在样本点上。</p><p>RaceID2是一种改进的聚类算法，能够将大量细胞进行聚类，从而确定不同细胞群/亚群的分界线。</p><h2 id="StemID"><a href="#StemID" class="headerlink" title="StemID"></a>StemID</h2><p>StemID是一种系谱图推导方法，StemID的系谱图推导基于RaceID2的聚类结果。</p><p>下面是从原文摘录的算法流程图：</p><p><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/2019-03-15-000000.jpg" alt=""></p><p>图A是RaceID2的聚类结果，其聚类中心都在样本点上。</p><p>这里先介绍作者给出的一个<strong>感性假设</strong>：每个节点 $k$ (一个细胞)除了属于自身的第 $i$ 类外，它还将连接到一个其它的某个类 $j$ ，这个类 $j$ 实际意义等同于另一个的细胞群/亚群，细胞 $k$ 将倾向于朝细胞群 $j$ 分化。</p><p>如图A所示，Cluster 1的聚类中心是 $m_i$，这里 $i=1$，将 $m_i$ 与其它所有聚类中进行连接（如图A黑色矢量）。第 $i$ 类中的节点 $k$（蓝色矢量箭头处）与类中心 $m_i$ 组成了一个向量（如图A蓝色矢量）。蓝色矢量将在所有黑色矢量上产生一个 <strong>投影</strong>。我们取与 <strong>最大投影长度</strong> 相对应的那个外类作为 <strong>感性假设</strong> 中陈述的潜在分化方向。</p><p>如图B2所示，将所有节点转换成到之相对应的投影位置，此时所有节点都将落到由聚类中心组成的网络上。</p><p>此网络就是StenID算法所构建的系谱树框架。</p><p>给网络的边打分：映射后不同边上点的分布是不同的，对于某条边 $L$ 上的任意两点 $r_i$ 和 $r_j$，定义打分公式：</p><p>$$score=1-\max_{i,j{\in}L}{||r_i-r_j||}$$ </p><p>当 $score{\to}0$ 时说明该边上所有点非常紧密的靠近聚类中心。</p><p>p值计算：重复采样，略</p><p>细胞的熵得计算：略</p><h2 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h2><p>作者自己分析了一下，在下面两种情况出现时算法可能不太灵光：</p><ol><li>出现中间过渡态细胞的样本缺失；</li><li>出现不直接关联的细胞。</li></ol><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><p>Cell Stem Cell. 2016 Aug 4;19(2):266-277. doi: 10.1016/j.stem.2016.05.010. Epub 2016 Jun 23.<br><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4985539/" target="_blank" rel="noopener">De Novo Prediction of Stem Cell Identity using Single-Cell Transcriptome Data</a><br>Grün D1, Muraro MJ2, Boisset JC2, Wiebrands K2, Lyubimova A2, Dharmadhikari G3, van den Born M2, van Es J2, Jansen E2, Clevers H4, de Koning EJP3, van Oudenaarden A5.</p><p>github：<a href="https://github.com/dgrun/StemID" target="_blank" rel="noopener">StemID</a><br>omicX：<a href="https://omictools.com/stemid-tool" target="_blank" rel="noopener">stemid-tool</a></p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;数据分析时要处理的噪声不仅来自实验误差和测量误差，基因表达和少量mRNA的扩增都会产生一定的噪声。其中来自生物过程的噪声可以通过大量测序来缓和。&lt;/p&gt;
&lt;p&gt;如果根据某一时刻的转录表达情况推断细胞系谱结构一直是一个严峻的挑战。作者肯定了&lt;a href=&quot;/生物信息学/20190315-643b.html&quot;&gt;Wanderlust算法&lt;/a&gt;的设计思想，但是同时对其设计的拓扑结构的合理性表示怀疑，并提出了自己的解决方案。&lt;/p&gt;
&lt;p&gt;RaceID2算法旨在：基于单细胞转录组数据，通过聚类鉴定出干细胞&lt;/p&gt;
&lt;p&gt;StemID算法旨在：利用RaceID2的聚类结果，构建系谱树&lt;/p&gt;
    
    </summary>
    
      <category term="生信工具和算法" scheme="http://chenyin.top/categories/%E7%94%9F%E4%BF%A1%E5%B7%A5%E5%85%B7%E5%92%8C%E7%AE%97%E6%B3%95/"/>
    
    
  </entry>
  
  <entry>
    <title>生信分析工具-Wanderlust</title>
    <link href="http://chenyin.top/%E7%94%9F%E4%BF%A1%E5%B7%A5%E5%85%B7%E5%92%8C%E7%AE%97%E6%B3%95/20190315-643b.html"/>
    <id>http://chenyin.top/生信工具和算法/20190315-643b.html</id>
    <published>2019-03-15T06:57:30.000Z</published>
    <updated>2019-03-25T14:58:18.869Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>以人类B细胞为例，确定每个细胞在相应细胞过程（例如细胞分化）中的先后顺序。</p><a id="more"></a><h1 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h1><p><strong>输入</strong>：算法的输入是一个 $M{\times}N$ 的矩阵，其中 $M$ 是细胞数量，$N$ 是选取的marker数量。每个marker的丰度由<strong>质谱流式细胞技术</strong>(Mass Cytometry)测定。</p><p><strong>输出</strong>：每个细胞的路径打分。此打分值介于0~1之间：0表示路径起点细胞，1代表路径终点细胞。</p><p>Wanderlust实际上就是<strong>最近邻图</strong>(Nearest Neighbour Graph)与<strong>EM算法</strong>的组合。</p><p>下图是摘自原文的算法流程：</p><p><img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/2019-03-15_153512.jpg" alt=""></p><p>图A是输入数据的形象表示。</p><p>1.凭先验知识确定一个<strong>起始节点</strong>（图B红色节点），<strong>随机</strong>确定 $nl$ 个<strong>路标节点</strong>（图B紫色节点）</p><p>为什么设置路标节点？路标节点起到缓冲噪声干扰的作用。相对于起始点，具有更小的<strong>最短路径距离</strong>（Shortest Path Distance）。而随机选取可以排除了先验知识的影响。</p><p>2.构建<strong>k-NNG</strong>，该图以<strong>邻接矩阵</strong>的方式进行存储，计算相连节点间的距离，可选的距离定义有欧式距离、余弦距离、……</p><p>3.NNG下采样：从这个k-NNG构造出 $l$ 个l-k-NNG。算法只在子图上迭代运行，最后取均值作为最终结果。</p><p>为什么采样成子图进行计算？前面构造的k-NNG实际上包含了许多与实际情况不符的连接，即“假边”。进一步的随机下采样使得这些“假边”在子图中出现一定程度的缺失，这将增强模型的适应能力（鲁棒性）。</p><p>对于每个子图进行迭代优化：</p><p>4.初始化每个节点（细胞）的路径打分；起始节点为0，终止节点为1，中间节点的初始打分为该节点到起始节点的最短路径距离。最短路径距离通过Dijkstra算法计算。</p><p>初始化两节点连接的方向：距离起始节点<strong>路径打分</strong>小的节点作为上游节点。</p><p>5.对每个目标节点 $t$ 和每个路标节点 $l$ 间的距离进行打分：</p><p>$$w_{l,t}=\frac{d(l,t)^2}{\sum_m{d(l,m)^2}}$$</p><p>这个打分有什么意义？尚未知晓</p><p>6.计算每个目标节点 $t$ 的路径打分，即该目标节点到所有路标节点距离的加权平均：</p><p>$$traj_t=\frac1{nl}\sum_l{w_{l,t}d(l,t)}$$</p><p>7.根据计算出来的路径打分计算新的方向。</p><p>8.重复步骤567直到路径打分收敛。</p><h1 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h1><p>Cell. 2014 Apr 24;157(3):714-25. doi: 10.1016/j.cell.2014.04.005.<br><a href="https://www.ncbi.nlm.nih.gov/pubmed/24766814" target="_blank" rel="noopener">Single-cell trajectory detection uncovers progression and regulatory coordination in human B cell development.</a><br>Bendall SC1, Davis KL2, Amir el-AD3, Tadmor MD3, Simonds EF4, Chen TJ5, Shenfeld DK3, Nolan GP6, Pe’er D7.</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;以人类B细胞为例，确定每个细胞在相应细胞过程（例如细胞分化）中的先后顺序。&lt;/p&gt;
    
    </summary>
    
      <category term="生信工具和算法" scheme="http://chenyin.top/categories/%E7%94%9F%E4%BF%A1%E5%B7%A5%E5%85%B7%E5%92%8C%E7%AE%97%E6%B3%95/"/>
    
    
  </entry>
  
  <entry>
    <title>win10系统激活</title>
    <link href="http://chenyin.top/OS%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C/20190301-83a5.html"/>
    <id>http://chenyin.top/OS学习手册/20190301-83a5.html</id>
    <published>2019-03-01T14:18:59.000Z</published>
    <updated>2019-03-26T14:34:31.662Z</updated>
    
    <content type="html"><![CDATA[<p>晚上打开公司发的个人电脑，桌面右下角的“激活windows”提示十分难受，遂上网了一下激活方法。</p><a id="more"></a><p><code>Win</code> + <code>X</code> 选择<strong>命令提示符(管理源)</strong>打开cmd</p><p>三行命令激活：<br><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">//Win10专业版(<span class="number">2019</span>年<span class="number">3</span>月<span class="number">26</span>日测试可用)</span><br><span class="line">slmgr /ipk W269N-WFGWX-YVC9B-<span class="number">4</span>J6C9-T83GX</span><br><span class="line">slmgr /skms kms.<span class="number">03</span>k.org</span><br><span class="line">slmgr /ato</span><br><span class="line"></span><br><span class="line">//Win10企业版</span><br><span class="line">slmgr /ipk NPPR9-FWDCX-D2C8J-H872K-<span class="number">2</span>YT43</span><br><span class="line">slmgr /skms kms.<span class="number">03</span>k.org</span><br><span class="line">slmgr /ato </span><br><span class="line"></span><br><span class="line">//Win10家庭版</span><br><span class="line">slmgr /ipk TX9XD-<span class="number">98</span>N7V-<span class="number">6</span>WMQ6-BX7FG-H8Q99</span><br><span class="line">slmgr /skms kms.<span class="number">03</span>k.org</span><br><span class="line">slmgr /ato</span><br></pre></td></tr></table></figure></p><p>Win10激活密钥key激活次数有限制，不能保证100%激活成功。</p><p><a href="https://blog.csdn.net/weixin_42588262/article/details/81120403" target="_blank" rel="noopener">2019年3月最新可用KMS激活服务器地址</a></p><p><a href="http://kms.cangshui.net/" target="_blank" rel="noopener">KMS一键激活服务</a></p><p><a href="https://03k.org/kms.html" target="_blank" rel="noopener">KMS一句命令激活windows/office</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;晚上打开公司发的个人电脑，桌面右下角的“激活windows”提示十分难受，遂上网了一下激活方法。&lt;/p&gt;
    
    </summary>
    
      <category term="OS学习手册" scheme="http://chenyin.top/categories/OS%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C/"/>
    
    
      <category term="win10" scheme="http://chenyin.top/tags/win10/"/>
    
      <category term="激活" scheme="http://chenyin.top/tags/%E6%BF%80%E6%B4%BB/"/>
    
  </entry>
  
  <entry>
    <title>监督学习-广义线性模型01-普通最小二乘法</title>
    <link href="http://chenyin.top/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/20190225-724a.html"/>
    <id>http://chenyin.top/机器学习与算法基础/20190225-724a.html</id>
    <published>2019-02-25T02:53:41.000Z</published>
    <updated>2019-03-25T14:58:45.702Z</updated>
    
    <content type="html"><![CDATA[<p>线性模型：输出是输入的线性组合，即：</p><p>$$y(w,x)=w_0+w_1x_1+\cdots+w_px_p$$ <a id="more"></a></p><p>在sklearn中，变量 <code>coef_</code> 存储向量 $w=(w_1,\cdots,w_p)$，变量 <code>intercept_</code> 存储 $w_0$。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br></pre></td></tr></table></figure><hr><h1 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h1><p><strong>普通最小二乘法</strong>(Ordinary Least Squares)就是简单的计算残差和：</p><p>$$min_w{||Xw-y||_2}^2$$</p><p>这个算法叫做 <strong>线性回归</strong>(Linear Regression):</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"></span><br><span class="line">estimator = linear_model.LineaRegression(...)</span><br></pre></td></tr></table></figure><p>简单的线性回归只在输入X数据集的各特征之间线性不相关时表现良好。</p><p>当X的特征线性相关时，估计结果受随机误差影响大，此时就需要进行模型的矫正。</p><hr><h1 id="脊回归-岭回归"><a href="#脊回归-岭回归" class="headerlink" title="脊回归/岭回归"></a>脊回归/岭回归</h1><p>当特征间 <strong>共线性</strong>（Collinearity）关系较强时，<strong>脊回归</strong>（Ridge Regression）可以使模型具有收缩能力。</p><p>这通过给线性回归添加L2正则项实现：</p><p>$$min_w{||Xw-y||_2}^2+\alpha{||w||_2}^2，其中\alpha\le0$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定关键超参数α的值</span></span><br><span class="line">estimator = linear_model.Ridge(alpha=<span class="number">0.5</span>)</span><br></pre></td></tr></table></figure><p>对于α，可以使用交叉验证进行最优解搜索：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"></span><br><span class="line"><span class="comment"># 给定α的取值范围，默认值如下</span></span><br><span class="line"><span class="comment"># cv指定交叉验证的折数，默认如下，默认使用留一交叉验证（Leave-One-Out CV）</span></span><br><span class="line">estimator = linear_model.RidgeCV(alpha=[<span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">10.0</span>], cv=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure><hr><h1 id="Lasso"><a href="#Lasso" class="headerlink" title="Lasso"></a>Lasso</h1><p>Lasso是用来估计稀疏系数的线性模型，和其变异体广泛用于语义压缩领域？</p><p>$$min_w\frac1{2n_{samples}}{||Xw-y||_2}^2+\alpha||w||_1，其中\alpha\le0$$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line"></span><br><span class="line"><span class="comment"># α默认值如下</span></span><br><span class="line">estimator = linear_model.Lasso(alpha=<span class="number">1.0</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;线性模型：输出是输入的线性组合，即：&lt;/p&gt;
&lt;p&gt;$$y(w,x)=w_0+w_1x_1+\cdots+w_px_p$$
    
    </summary>
    
      <category term="机器学习与算法基础" scheme="http://chenyin.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%8E%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80/"/>
    
    
  </entry>
  
  <entry>
    <title>获得一组数的全排列</title>
    <link href="http://chenyin.top/python%E7%BC%96%E7%A8%8B/20190221-9924.html"/>
    <id>http://chenyin.top/python编程/20190221-9924.html</id>
    <published>2019-02-21T08:24:14.000Z</published>
    <updated>2019-03-25T14:59:35.735Z</updated>
    
    <content type="html"><![CDATA[<p>自己实现的python函数。<a id="more"></a><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">permutation</span><span class="params">(xs)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> isinstance(xs,str):</span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">str2charArray</span><span class="params">(str)</span>:</span></span><br><span class="line">            charArray = []</span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> str:</span><br><span class="line">                charArray.append(i)</span><br><span class="line">            <span class="keyword">return</span> charArray</span><br><span class="line">        xs = str2charArray(xs)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> len(xs) == <span class="number">0</span> <span class="keyword">or</span> len(xs) == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> [xs]</span><br><span class="line"></span><br><span class="line">    result = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,len(xs)):</span><br><span class="line">        temp_list = xs[:]</span><br><span class="line">        temp_list.pop(i)</span><br><span class="line">        temp = permutation(temp_list)</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> temp:</span><br><span class="line">            j.insert(<span class="number">0</span>,xs[i])</span><br><span class="line">            result.append(j)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;自己实现的python函数。
    
    </summary>
    
      <category term="python编程" scheme="http://chenyin.top/categories/python%E7%BC%96%E7%A8%8B/"/>
    
    
  </entry>
  
  <entry>
    <title>glob内建模块</title>
    <link href="http://chenyin.top/python%E7%BC%96%E7%A8%8B/20190221-3133.html"/>
    <id>http://chenyin.top/python编程/20190221-3133.html</id>
    <published>2019-02-21T07:28:59.000Z</published>
    <updated>2019-03-25T15:00:03.411Z</updated>
    
    <content type="html"><![CDATA[<p><strong>glob模块</strong>是python的一个很基础、很简单的模块，用于匹配文件路径。<a id="more"></a></p><p>glob这个单词本身有“通配符”的意思，通配的一个很关键的应用就是筛选出符合条件的文件。</p><p>与python的另一个专门用于正则匹配的 <strong>re模块</strong> 不同，glob只需要三个通配符：<code>*</code>、<code>？</code>、<code>[]</code>。</p><p>以下是常见的匹配情形：</p><ol><li><code>glob.glob(&#39;/a/b/*.txt&#39;)</code>: 匹配目录 <code>/a/b/</code> 下的所有.txt文件</li><li><code>glob.glob(&#39;/a/b/^[xyz]*.txt&#39;)</code>: 匹配目录 <code>/a/b/</code> 下所有文件名以字母xyz中任意一个开始的文件</li><li><code>glob.glob(&#39;/a/*/*.txt&#39;)</code>: 匹配目录 <code>/a/</code> 下所有的.txt文件</li></ol><p>此外，<code>glob.glob()</code> 是一次查询完所有结果。在查询结果较多时，可以使用 <code>glob.iglob()</code> 迭代查询，<code>glob.iglob()</code> 返回一个<strong>生成器</strong>。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;glob模块&lt;/strong&gt;是python的一个很基础、很简单的模块，用于匹配文件路径。
    
    </summary>
    
      <category term="python编程" scheme="http://chenyin.top/categories/python%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="python模块" scheme="http://chenyin.top/tags/python%E6%A8%A1%E5%9D%97/"/>
    
  </entry>
  
  <entry>
    <title>os内建模块</title>
    <link href="http://chenyin.top/python%E7%BC%96%E7%A8%8B/20190104-af30.html"/>
    <id>http://chenyin.top/python编程/20190104-af30.html</id>
    <published>2019-01-04T04:55:50.000Z</published>
    <updated>2019-03-25T15:00:21.618Z</updated>
    
    <content type="html"><![CDATA[<p><strong>os模块</strong>用于处理文件系统中的文件和目录。<a id="more"></a></p><h1 id="工作目录"><a href="#工作目录" class="headerlink" title="工作目录"></a>工作目录</h1><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>os.getcwd()</td><td>当前脚本文件的工作目录</td></tr><tr><td>os.chdir(DIR)</td><td>切换工作目录至DIR，默认工作目录为脚本所在目录</td></tr></tbody></table><h1 id="目录的增删查改"><a href="#目录的增删查改" class="headerlink" title="目录的增删查改"></a>目录的增删查改</h1><table><thead><tr><th>新建目录</th></tr></thead><tbody><tr><td>os.mkdir(“A/B/“)</td><td>创建一个目录A/B/，不能递归创建，即要求目录A存在</td></tr><tr><td>os.makedirs(DIR)</td><td>创建一个目录DIR，与上面不同的是，可以递归创建目录</td></tr></tbody></table><table><thead><tr><th>删除目录</th></tr></thead><tbody><tr><td>os.rmdir(DIR)</td><td>当目录DIR为空时删除目录，不为空时报错</td></tr><tr><td>os.removedirs(DIR)</td><td>待查</td></tr></tbody></table><table><thead><tr><th>列举目录</th></tr></thead><tbody><tr><td>os.listdir(DIR)</td><td>列出<strong>直接</strong>属于目录DIR的文件和子目录</td></tr><tr><td>os.walk(DIR)</td><td>遍历目录DIR下所有的文件和目录，返回<strong>生成器</strong>，返回结果较复杂，待查</td></tr></tbody></table><table><thead><tr><th>文件和目录的重命名</th></tr></thead><tbody><tr><td>os.rename(OLD_NAME, NEW_NAME)</td><td></td></tr><tr><td>os.system(“COMMAMD_STRING”)</td><td>调用shell命令进行重命名</td></tr></tbody></table><h1 id="路径操作"><a href="#路径操作" class="headerlink" title="路径操作"></a>路径操作</h1><table><thead><tr><th>路径类型判断</th></tr></thead><tbody><tr><td>os.path.isfile(PATH)</td><td>判断是否为文件，是文件返回<code>True</code></td></tr><tr><td>os.path.isdir(PATH)</td><td>判断是否为目录，是目录返回 <code>True</code></td></tr><tr><td>os.path.exists(PATH)</td><td>判断是否存在，存在返回 <code>True</code></td></tr><tr><td>os.path.getsize(PATH)</td><td>是文件返回文件大小，是目录返回0</td></tr></tbody></table><table><thead><tr><th>路径的切割、合并</th></tr></thead><tbody><tr><td>os.path.split(‘1/2/3’)</td><td>分割成目录和文件，得到 <code>(&#39;1/2&#39;,&#39;3&#39;)</code></td></tr><tr><td>os.path.split(‘1/2/3/‘)</td><td>分割成目录和文件，得到 <code>(&#39;1/23&#39;,&#39;&#39;)</code></td></tr><tr><td>os.splitext(‘path/name.txt’)</td><td>分割出文件后缀，得到 <code>(&#39;path/name&#39;, &#39;.txt&#39;)</code></td></tr></tbody></table><table><thead><tr><th>路径的连接</th></tr></thead><tbody><tr><td>os.path.join(A, B)</td><td>使用默认路径分割符连接两个字符串，得到 <code>&quot;A/B&quot;</code></td></tr></tbody></table><h1 id="常量"><a href="#常量" class="headerlink" title="常量"></a>常量</h1><table><thead><tr><th></th><th></th></tr></thead><tbody><tr><td>os.sep 或 os.path.sep</td><td>当前系统下是使用的 <strong>路径分割符</strong></td></tr><tr><td>os.linesep</td><td>当前系统下使用的 <strong>行终止符</strong></td></tr><tr><td>os.environ</td><td>字典：环境变量</td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;os模块&lt;/strong&gt;用于处理文件系统中的文件和目录。
    
    </summary>
    
      <category term="python编程" scheme="http://chenyin.top/categories/python%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="python模块" scheme="http://chenyin.top/tags/python%E6%A8%A1%E5%9D%97/"/>
    
  </entry>
  
  <entry>
    <title>获取当前文件所在的目录</title>
    <link href="http://chenyin.top/python%E7%BC%96%E7%A8%8B/20190103-5c31.html"/>
    <id>http://chenyin.top/python编程/20190103-5c31.html</id>
    <published>2019-01-03T07:45:21.000Z</published>
    <updated>2019-03-25T15:01:26.702Z</updated>
    
    <content type="html"><![CDATA[<p>记录下常用的方法。<a id="more"></a></p><h1 id="利用os模块"><a href="#利用os模块" class="headerlink" title="利用os模块"></a>利用os模块</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 当前脚本文件所在的目录（工作目录）</span></span><br><span class="line">os.getcwd() <span class="comment"># Get current work directory</span></span><br></pre></td></tr></table></figure><p>这个方法不一定得到正确结果！</p><h1 id="利用内建数组sys-argv"><a href="#利用内建数组sys-argv" class="headerlink" title="利用内建数组sys.argv"></a>利用内建数组sys.argv</h1><p><code>sys.argv</code> 数组的第一个值（<code>sys.argv[0]</code>）存储的永远是当前脚本文件的绝对路径。</p><p>从这个路径中去掉文件名就是当前脚本文件所在目录的绝对路径。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># current file directory</span></span><br><span class="line">cur_fdir = os.path.split(sys.argv[<span class="number">0</span>])[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;记录下常用的方法。
    
    </summary>
    
      <category term="python编程" scheme="http://chenyin.top/categories/python%E7%BC%96%E7%A8%8B/"/>
    
    
      <category term="青铜派森" scheme="http://chenyin.top/tags/%E9%9D%92%E9%93%9C%E6%B4%BE%E6%A3%AE/"/>
    
  </entry>
  
  <entry>
    <title>博客改造计划</title>
    <link href="http://chenyin.top/%E5%BF%AB%E6%8D%B7%E6%B8%85%E5%8D%95/20190102-19a0.html"/>
    <id>http://chenyin.top/快捷清单/20190102-19a0.html</id>
    <published>2019-01-02T04:13:34.000Z</published>
    <updated>2019-03-25T15:02:26.005Z</updated>
    
    <content type="html"><![CDATA[<p>比较有意思的优化过程。<a id="more"></a></p><h1 id="博文置顶"><a href="#博文置顶" class="headerlink" title="博文置顶"></a>博文置顶</h1><p>修改hexo-generator-index插件：备份文件<code>node_modules/hexo-generator-index/lib/generator.js</code>并将其中代码替换为：<br><figure class="highlight js"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">'use strict'</span>;</span><br><span class="line"><span class="keyword">var</span> pagination = <span class="built_in">require</span>(<span class="string">'hexo-pagination'</span>);</span><br><span class="line"><span class="built_in">module</span>.exports = <span class="function"><span class="keyword">function</span>(<span class="params">locals</span>)</span>&#123;</span><br><span class="line">  <span class="keyword">var</span> config = <span class="keyword">this</span>.config;</span><br><span class="line">  <span class="keyword">var</span> posts = locals.posts;</span><br><span class="line">    posts.data = posts.data.sort(<span class="function"><span class="keyword">function</span>(<span class="params">a, b</span>) </span>&#123;</span><br><span class="line"><span class="comment">// 两篇文章top都有定义</span></span><br><span class="line">        <span class="keyword">if</span>(a.top &amp;&amp; b.top) &#123; </span><br><span class="line"><span class="comment">// 若top值一样则按照文章日期降序排</span></span><br><span class="line">            <span class="keyword">if</span>(a.top == b.top) <span class="keyword">return</span> b.date - a.date; </span><br><span class="line"><span class="comment">// 否则按照top值降序排</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">return</span> b.top - a.top; </span><br><span class="line">        &#125;</span><br><span class="line"><span class="comment">// 以下是只有一篇文章top有定义，那么将有top的排在前面（这里用异或操作居然不行233）</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(a.top &amp;&amp; !b.top) &#123; </span><br><span class="line">            <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(!a.top &amp;&amp; b.top) &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line"><span class="comment">// 都没定义按照文章日期降序排</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> b.date - a.date; </span><br><span class="line">    &#125;);</span><br><span class="line">  <span class="keyword">var</span> paginationDir = config.pagination_dir || <span class="string">'page'</span>;</span><br><span class="line">  <span class="keyword">return</span> pagination(<span class="string">''</span>, posts, &#123;</span><br><span class="line">    perPage: config.index_generator.per_page,</span><br><span class="line">    layout: [<span class="string">'index'</span>, <span class="string">'archive'</span>],</span><br><span class="line">    format: paginationDir + <span class="string">'/%d/'</span>,</span><br><span class="line">    data: &#123;</span><br><span class="line">      __index: <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p><p>设置<code>hexo new</code>生成博文时自动添加<strong>top</strong>元数据：将<code>top:</code>添加到文件<code>scaffolds\post.md</code>:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">---</span><br><span class="line">title: &#123;&#123; title &#125;&#125;</span><br><span class="line">date: &#123;&#123; date &#125;&#125;</span><br><span class="line">categories: </span><br><span class="line">top: </span><br><span class="line">tags:</span><br><span class="line">---</span><br></pre></td></tr></table></figure></p><p>设置top值即可，top值越大，文章越靠前</p><hr><h1 id="fork-me-on-github"><a href="#fork-me-on-github" class="headerlink" title="fork me on github"></a>fork me on github</h1><p>效果如下：<img src="http://barwe-blog.oss-cn-shenzhen.aliyuncs.com/blogImgs/2019/03/2019-03-23_104518.png" alt=""></p><p>在<code>themes\next\layout\_layout.swig</code>中搜索<code>&lt;div class=&quot;headband&quot;&gt;&lt;/div&gt;</code>找到如下位置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;div class=&quot;headband&quot;&gt;&lt;/div&gt;</span><br><span class="line">&lt;!-- 这个地方 --&gt;</span><br><span class="line">&lt;header id=&quot;header&quot; class=&quot;header&quot; itemscope itemtype=&quot;http://schema.org/WPHeader&quot;&gt;</span><br></pre></td></tr></table></figure></p><p>添加代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- fork me on github begin --&gt;</span><br><span class="line">&lt;!-- 默认启用右上角图标，需要换成左上角请更换注释部分 --&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 右上角 --&gt;</span><br><span class="line">&lt;a href=&quot;https://github.com/barwe&quot; class=&quot;github-corner&quot; aria-label=&quot;View source on GitHub&quot;&gt;</span><br><span class="line">&lt;svg width=&quot;80&quot; height=&quot;80&quot; viewBox=&quot;0 0 250 250&quot;</span><br><span class="line"> class=&quot;fork-me-on-github&quot;</span><br><span class="line"> style=&quot;position: absolute; border: 0;&quot; aria-hidden=&quot;true&quot;&gt;</span><br><span class="line"> &lt;path d=&quot;M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z&quot;&gt;&lt;/path&gt;</span><br><span class="line"> &lt;path d=&quot;M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2&quot; fill=&quot;currentColor&quot; style=&quot;transform-origin: 130px 106px;&quot; class=&quot;octo-arm&quot;&gt;&lt;/path&gt;</span><br><span class="line"> &lt;path d=&quot;M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z&quot; fill=&quot;currentColor&quot; class=&quot;octo-body&quot;&gt;&lt;/path&gt;</span><br><span class="line">&lt;/svg&gt;</span><br><span class="line">&lt;/a&gt;</span><br><span class="line">&lt;style&gt;</span><br><span class="line">.github-corner:hover .octo-arm&#123;animation:octocat-wave 560ms ease-in-out&#125;</span><br><span class="line">@keyframes octocat-wave&#123;0%,100%&#123;transform:rotate(0)&#125;20%,60%&#123;transform:rotate(-25deg)&#125;40%,80%&#123;transform:rotate(10deg)&#125;&#125;</span><br><span class="line">@media (max-width:500px)&#123;</span><br><span class="line">.github-corner:hover .octo-arm&#123;animation:none&#125;</span><br><span class="line">.github-corner .octo-arm&#123;animation:octocat-wave 560ms ease-in-out&#125;</span><br><span class="line">&#125;</span><br><span class="line">&lt;/style&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 左上角</span><br><span class="line">&lt;a href=&quot;https://github.com/barwe&quot; class=&quot;github-corner&quot; aria-label=&quot;View source on GitHub&quot;&gt;</span><br><span class="line">&lt;svg width=&quot;80&quot; height=&quot;80&quot; viewBox=&quot;0 0 250 250&quot; </span><br><span class="line"> class=&quot;fork-me-on-github&quot;</span><br><span class="line"> style=&quot;position: absolute; border: 0; transform: scale(-1, 1);&quot; aria-hidden=&quot;true&quot;&gt;</span><br><span class="line">&lt;path d=&quot;M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z&quot;&gt;&lt;/path&gt;</span><br><span class="line">&lt;path d=&quot;M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2&quot; fill=&quot;currentColor&quot; style=&quot;transform-origin: 130px 106px;&quot; class=&quot;octo-arm&quot;&gt;&lt;/path&gt;</span><br><span class="line">&lt;path d=&quot;M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z&quot; fill=&quot;currentColor&quot; class=&quot;octo-body&quot;&gt;&lt;/path&gt;</span><br><span class="line">&lt;/svg&gt;</span><br><span class="line">&lt;style&gt;</span><br><span class="line">.github-corner:hover .octo-arm&#123;animation:octocat-wave 560ms ease-in-out&#125;</span><br><span class="line">@keyframes octocat-wave&#123;0%,100%&#123;transform:rotate(0)&#125;20%,60%&#123;transform:rotate(-25deg)&#125;40%,80%&#123;transform:rotate(10deg)&#125;&#125;</span><br><span class="line">@media (max-width:500px)&#123;</span><br><span class="line">.github-corner:hover .octo-arm&#123;animation:none&#125;</span><br><span class="line">.github-corner .octo-arm&#123;animation:octocat-wave 560ms ease-in-out&#125;</span><br><span class="line">&#125;</span><br><span class="line">&lt;/style&gt;</span><br><span class="line">&lt;/a&gt;</span><br><span class="line">--&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- fork me on github end --&gt;</span><br></pre></td></tr></table></figure></p><p>在<code>themes\next\source\css\_custom\custom.styl</code>文件中添加：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">//在右上角或者左上角添加fork me on github图块</span><br><span class="line">.fork-me-on-github &#123;</span><br><span class="line">fill: red // 背景色</span><br><span class="line">color: white // 猫的颜色</span><br><span class="line">top: 0</span><br><span class="line">right: 0 // 在右上角</span><br><span class="line">//left: 0 // 在左上角</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>这个功能刷新可能需要重启服务器。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;比较有意思的优化过程。
    
    </summary>
    
      <category term="快捷清单" scheme="http://chenyin.top/categories/%E5%BF%AB%E6%8D%B7%E6%B8%85%E5%8D%95/"/>
    
    
  </entry>
  
  <entry>
    <title>Linux系统信息查询</title>
    <link href="http://chenyin.top/OS%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C/20190101-1ff5.html"/>
    <id>http://chenyin.top/OS学习手册/20190101-1ff5.html</id>
    <published>2019-01-01T13:53:38.000Z</published>
    <updated>2019-03-25T15:02:49.835Z</updated>
    
    <content type="html"><![CDATA[<p>emmmmmm,先记下来…… <a id="more"></a></p><h1 id="系统"><a href="#系统" class="headerlink" title="系统"></a>系统</h1><p><code>uname -a</code>：内核、操作系统、CPU信息</p><p><code>head -n 1 /etc/issue</code>：操作系统版本</p><p><code>cat /proc/cpuinfo</code>：CPU信息</p><p><code>hostname</code>：计算机名</p><p><code>lspci -tv</code>：列出所有PCI设备</p><p><code>lsusb -tv</code>：列出所有USB设备</p><p><code>lsmod</code>：列出加载的内核模块</p><p><code>env</code>：查看环境变量</p><h1 id="内存与资源"><a href="#内存与资源" class="headerlink" title="内存与资源"></a>内存与资源</h1><p><code>free -m</code>：查看内存使用量和交换区使用量</p><p><code>df -h</code>：查看各分区使用情况</p><p><code>du -sh DIR</code>：查看目录DIR的大小，非本人的目录可能要使用 <code>sudo</code> 提权</p><p><code>grep MemTotal /proc/meminfo</code>：查看内存总量</p><p><code>grep MemFree /proc/meninfo</code>：查看空闲内存量</p><p><code>uptime</code>：查看系统运行时间、用户数、负载</p><p><code>cat /proc/loadavg</code>：查看系统负载</p><h1 id="磁盘和分区信息"><a href="#磁盘和分区信息" class="headerlink" title="磁盘和分区信息"></a>磁盘和分区信息</h1><p><code>mount | column -t</code>：查看挂接的分区状态</p><p><code>fdisk -l</code>：查看所有分区</p><p><code>swapon -s</code>：查看所有交换分区</p><p><code>hdparm -i /dev/hda</code>：查看磁盘参数</p><p><code>dmesg | grep IDE</code>：查看启动时IDE设备检测状况</p><h1 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h1><p><code>ifconfig</code>：查看所有网络接口的属性</p><p><code>iptables -L</code>：查看防火墙设置</p><p><code>route -n</code>：查看路由表</p><p><code>netstat -lntp</code>：查看所有监听端口</p><p><code>netstat -antp</code>：查看所有已经建立的连接</p><p><code>netstat -s</code>：查看网络统计信息</p><h1 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h1><p><code>ps -ef</code>：查看所有进程</p><p><code>top</code>：是实现显示进程状态</p><h1 id="用户"><a href="#用户" class="headerlink" title="用户"></a>用户</h1><p><code>w</code>：查看活动用户</p><p><code>id USERNAME</code>：查看用户USERNAME的信息</p><p><code>last</code>：查看用户登录日志</p><p><code>cut -d: -f1 /etc/passwd</code>：查看系统所有用户</p><p><code>cut -d: -f1 /etc/group</code>：查看系统所有组</p><p><code>crontab -l</code>：查看当前用户的计划任务</p><h1 id="服务"><a href="#服务" class="headerlink" title="服务"></a>服务</h1><p><code>chkconfig --list</code>：列出所有系统服务</p><p><code>chkconfig  --list | grep on</code>：列出所有启动的系统任务</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;emmmmmm,先记下来……
    
    </summary>
    
      <category term="OS学习手册" scheme="http://chenyin.top/categories/OS%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C/"/>
    
    
      <category term="知识手册" scheme="http://chenyin.top/tags/%E7%9F%A5%E8%AF%86%E6%89%8B%E5%86%8C/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu16.04LTS修改软件源</title>
    <link href="http://chenyin.top/OS%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C/20181122-a661.html"/>
    <id>http://chenyin.top/OS学习手册/20181122-a661.html</id>
    <published>2018-11-21T16:07:36.000Z</published>
    <updated>2019-03-25T15:03:32.422Z</updated>
    
    <content type="html"><![CDATA[<p>修改软件源能大大加快软件更新和下载速度。<a id="more"></a></p><p>1、备份原始源：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mv /etc/apt/sources.list /etc/apt/sources.list.bak</span><br></pre></td></tr></table></figure><p>2、新建源：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vim /etc/apt/sources.list</span><br></pre></td></tr></table></figure><p>写入以下内容（对于Ubuntu16.04LTS）：</p><pre># 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-updates main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-backports main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-backports main restricted universe multiversedeb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-security main restricted universe multiverse# 预发布软件源，不建议启用# deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse# deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ xenial-proposed main restricted universe multiverse</pre><p>其他版本的源列表可以在 <a href="https://mirror.tuna.tsinghua.edu.cn/help/ubuntu/" target="_blank" rel="noopener">这里</a> 查看。</p><p>3、刷新：<code>sudo apt-get update</code></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;修改软件源能大大加快软件更新和下载速度。
    
    </summary>
    
      <category term="OS学习手册" scheme="http://chenyin.top/categories/OS%E5%AD%A6%E4%B9%A0%E6%89%8B%E5%86%8C/"/>
    
    
  </entry>
  
</feed>
